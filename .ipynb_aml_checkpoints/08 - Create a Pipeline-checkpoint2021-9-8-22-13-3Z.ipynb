{
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Create a Pipeline\n",
        "\n",
        "You can perform the various steps required to ingest data, train a model, and register the model individually by using the Azure ML SDK to run script-based experiments. However, in an enterprise environment it is common to encapsulate the sequence of discrete steps required to build a machine learning solution into a *pipeline* that can be run on one or more compute targets; either on-demand by a user, from an automated build process, or on a schedule.\n",
        "\n",
        "In this notebook, you'll bring together all of these elements to create a simple pipeline that pre-processes data and then trains and registers a model."
      ],
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Connect to your workspace\n",
        "\n",
        "To get started, connect to your workspace.\n",
        "\n",
        "> **Note**: If you haven't already established an authenticated session with your Azure subscription, you'll be prompted to authenticate by clicking a link, entering an authentication code, and signing into Azure."
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "import azureml.core\n",
        "from azureml.core import Workspace\n",
        "\n",
        "# Load the workspace from the saved config file\n",
        "ws = Workspace.from_config()\n",
        "print('Ready to use Azure ML {} to work with {}'.format(azureml.core.VERSION, ws.name))"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "Ready to use Azure ML 1.34.0 to work with ict-915-02-jmdl\n"
        }
      ],
      "execution_count": 1,
      "metadata": {
        "gather": {
          "logged": 1633727849312
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Prepare data\n",
        "\n",
        "In your pipeline, you'll use a dataset containing details of diabetes patients. Run the cell below to create this dataset (if you created it previously, the code will find the existing version)"
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "from azureml.core import Dataset\n",
        "\n",
        "default_ds = ws.get_default_datastore()\n",
        "\n",
        "if 'diabetes dataset' not in ws.datasets:\n",
        "    default_ds.upload_files(files=['./data/diabetes.csv', './data/diabetes2.csv'], # Upload the diabetes csv files in /data\n",
        "                        target_path='diabetes-data/', # Put it in a folder path in the datastore\n",
        "                        overwrite=True, # Replace existing files of the same name\n",
        "                        show_progress=True)\n",
        "\n",
        "    #Create a tabular dataset from the path on the datastore (this may take a short while)\n",
        "    tab_data_set = Dataset.Tabular.from_delimited_files(path=(default_ds, 'diabetes-data/*.csv'))\n",
        "\n",
        "    # Register the tabular dataset\n",
        "    try:\n",
        "        tab_data_set = tab_data_set.register(workspace=ws, \n",
        "                                name='diabetes dataset',\n",
        "                                description='diabetes data',\n",
        "                                tags = {'format':'CSV'},\n",
        "                                create_new_version=True)\n",
        "        print('Dataset registered.')\n",
        "    except Exception as ex:\n",
        "        print(ex)\n",
        "else:\n",
        "    print('Dataset already registered.')"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "Dataset already registered.\n"
        }
      ],
      "execution_count": 2,
      "metadata": {
        "gather": {
          "logged": 1633727884724
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Create scripts for pipeline steps\n",
        "\n",
        "Pipelines consist of one or more *steps*, which can be Python scripts, or specialized steps like a data transfer step that copies data from one location to another. Each step can run in its own compute context. In this exercise, you'll build a simple pipeline that contains two Python script steps: one to pre-process some training data, and another to use the pre-processed data to train and register a model.\n",
        "\n",
        "First, let's create a folder for the script files we'll use in the pipeline steps."
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "# Create a folder for the pipeline step files\n",
        "experiment_folder = 'diabetes_pipeline'\n",
        "os.makedirs(experiment_folder, exist_ok=True)\n",
        "\n",
        "print(experiment_folder)"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "diabetes_pipeline\n"
        }
      ],
      "execution_count": 3,
      "metadata": {
        "gather": {
          "logged": 1633727905464
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Now let's create the first script, which will read data from the diabetes dataset and apply some simple pre-processing to remove any rows with missing data and normalize the numeric features so they're on a similar scale.\n",
        "\n",
        "The script includes a argument named **--prepped-data**, which references the folder where the resulting data should be saved."
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "%%writefile $experiment_folder/prep_diabetes.py\n",
        "# Import libraries\n",
        "import os\n",
        "import argparse\n",
        "import pandas as pd\n",
        "from azureml.core import Run\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "\n",
        "# Get parameters\n",
        "parser = argparse.ArgumentParser()\n",
        "\n",
        "parser.add_argument(\"--input-data\", type=str, dest='raw_dataset_id', help='raw dataset')\n",
        "parser.add_argument('--prepped-data', type=str, dest='prepped_data', default='prepped_data', help='Folder for results')\n",
        "\n",
        "args = parser.parse_args()\n",
        "save_folder = args.prepped_data\n",
        "\n",
        "# Get the experiment run context\n",
        "run = Run.get_context()\n",
        "\n",
        "# load the data (passed as an input dataset)\n",
        "print(\"Loading Data...\")\n",
        "diabetes = run.input_datasets['raw_data'].to_pandas_dataframe()\n",
        "\n",
        "# Log raw row count\n",
        "row_count = (len(diabetes))\n",
        "run.log('raw_rows', row_count)\n",
        "\n",
        "# remove nulls\n",
        "diabetes = diabetes.dropna()\n",
        "\n",
        "# Normalize the numeric columns\n",
        "scaler = MinMaxScaler()\n",
        "num_cols = ['Pregnancies','PlasmaGlucose','DiastolicBloodPressure','TricepsThickness','SerumInsulin','BMI','DiabetesPedigree']\n",
        "diabetes[num_cols] = scaler.fit_transform(diabetes[num_cols])\n",
        "\n",
        "# Log processed rows\n",
        "row_count = (len(diabetes))\n",
        "run.log('processed_rows', row_count)\n",
        "\n",
        "# Save the prepped data\n",
        "print(\"Saving Data...\")\n",
        "os.makedirs(save_folder, exist_ok=True)\n",
        "save_path = os.path.join(save_folder,'data.csv')\n",
        "diabetes.to_csv(save_path, index=False, header=True)\n",
        "\n",
        "# End the run\n",
        "run.complete()"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "Writing diabetes_pipeline/prep_diabetes.py\n"
        }
      ],
      "execution_count": 4,
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": [
        "Now you can create the script for the second step, which will train a model. The script includes a argument named **--training-data**, which references the location where the prepared data was saved by the previous step."
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "%%writefile $experiment_folder/train_diabetes.py\n",
        "# Import libraries\n",
        "from azureml.core import Run, Model\n",
        "import argparse\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import joblib\n",
        "import os\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.metrics import roc_auc_score\n",
        "from sklearn.metrics import roc_curve\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Get parameters\n",
        "parser = argparse.ArgumentParser()\n",
        "parser.add_argument(\"--training-data\", type=str, dest='training_data', help='training data')\n",
        "args = parser.parse_args()\n",
        "training_data = args.training_data\n",
        "\n",
        "# Get the experiment run context\n",
        "run = Run.get_context()\n",
        "\n",
        "# load the prepared data file in the training folder\n",
        "print(\"Loading Data...\")\n",
        "file_path = os.path.join(training_data,'data.csv')\n",
        "diabetes = pd.read_csv(file_path)\n",
        "\n",
        "# Separate features and labels\n",
        "X, y = diabetes[['Pregnancies','PlasmaGlucose','DiastolicBloodPressure','TricepsThickness','SerumInsulin','BMI','DiabetesPedigree','Age']].values, diabetes['Diabetic'].values\n",
        "\n",
        "# Split data into training set and test set\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.30, random_state=0)\n",
        "\n",
        "# Train adecision tree model\n",
        "print('Training a decision tree model...')\n",
        "model = DecisionTreeClassifier().fit(X_train, y_train)\n",
        "\n",
        "# calculate accuracy\n",
        "y_hat = model.predict(X_test)\n",
        "acc = np.average(y_hat == y_test)\n",
        "print('Accuracy:', acc)\n",
        "run.log('Accuracy', np.float(acc))\n",
        "\n",
        "# calculate AUC\n",
        "y_scores = model.predict_proba(X_test)\n",
        "auc = roc_auc_score(y_test,y_scores[:,1])\n",
        "print('AUC: ' + str(auc))\n",
        "run.log('AUC', np.float(auc))\n",
        "\n",
        "# plot ROC curve\n",
        "fpr, tpr, thresholds = roc_curve(y_test, y_scores[:,1])\n",
        "fig = plt.figure(figsize=(6, 4))\n",
        "# Plot the diagonal 50% line\n",
        "plt.plot([0, 1], [0, 1], 'k--')\n",
        "# Plot the FPR and TPR achieved by our model\n",
        "plt.plot(fpr, tpr)\n",
        "plt.xlabel('False Positive Rate')\n",
        "plt.ylabel('True Positive Rate')\n",
        "plt.title('ROC Curve')\n",
        "run.log_image(name = \"ROC\", plot = fig)\n",
        "plt.show()\n",
        "\n",
        "# Save the trained model in the outputs folder\n",
        "print(\"Saving model...\")\n",
        "os.makedirs('outputs', exist_ok=True)\n",
        "model_file = os.path.join('outputs', 'diabetes_model.pkl')\n",
        "joblib.dump(value=model, filename=model_file)\n",
        "\n",
        "# Register the model\n",
        "print('Registering model...')\n",
        "Model.register(workspace=run.experiment.workspace,\n",
        "               model_path = model_file,\n",
        "               model_name = 'diabetes_model',\n",
        "               tags={'Training context':'Pipeline'},\n",
        "               properties={'AUC': np.float(auc), 'Accuracy': np.float(acc)})\n",
        "\n",
        "\n",
        "run.complete()"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "Writing diabetes_pipeline/train_diabetes.py\n"
        }
      ],
      "execution_count": 5,
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Prepare a compute environment for the pipeline steps\n",
        "\n",
        "In this exercise, you'll use the same compute for both steps, but it's important to realize that each step is run independently; so you could specify different compute contexts for each step if appropriate.\n",
        "\n",
        "First, get the compute target you created in a previous lab (if it doesn't exist, it will be created).\n",
        "\n",
        "> **Important**: Change *your-compute-cluster* to the name of your compute cluster in the code below before running it! Cluster names must be globally unique names between 2 to 16 characters in length. Valid characters are letters, digits, and the - character."
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "from azureml.core.compute import ComputeTarget, AmlCompute\n",
        "from azureml.core.compute_target import ComputeTargetException\n",
        "\n",
        "cluster_name = \"CT-915-02-JMDL\"\n",
        "\n",
        "try:\n",
        "    # Check for existing compute target\n",
        "    pipeline_cluster = ComputeTarget(workspace=ws, name=cluster_name)\n",
        "    print('Found existing cluster, use it.')\n",
        "except ComputeTargetException:\n",
        "    # If it doesn't already exist, create it\n",
        "    try:\n",
        "        compute_config = AmlCompute.provisioning_configuration(vm_size='STANDARD_DS11_V2', max_nodes=2)\n",
        "        pipeline_cluster = ComputeTarget.create(ws, cluster_name, compute_config)\n",
        "        pipeline_cluster.wait_for_completion(show_output=True)\n",
        "    except Exception as ex:\n",
        "        print(ex)\n",
        "    "
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "Found existing cluster, use it.\n"
        }
      ],
      "execution_count": 6,
      "metadata": {
        "gather": {
          "logged": 1633728436267
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "> **Note**: Compute instances and clusters are based on standard Azure virtual machine images. For this exercise, the *Standard_DS11_v2* image is recommended to achieve the optimal balance of cost and performance. If your subscription has a quota that does not include this image, choose an alternative image; but bear in mind that a larger image may incur higher cost and a smaller image may not be sufficient to complete the tasks. Alternatively, ask your Azure administrator to extend your quota.\n",
        "\n",
        "The compute will require a Python environment with the necessary package dependencies installed."
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "%%writefile $experiment_folder/experiment_env.yml\n",
        "name: experiment_env\n",
        "dependencies:\n",
        "- python=3.6.2\n",
        "- scikit-learn\n",
        "- ipykernel\n",
        "- matplotlib\n",
        "- pandas\n",
        "- pip\n",
        "- pip:\n",
        "  - azureml-defaults\n",
        "  - pyarrow"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "Writing diabetes_pipeline/experiment_env.yml\n"
        }
      ],
      "execution_count": 7,
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": [
        "Now that you have a Conda configuration file, you can create an environment and use it in the run configuration for the pipeline."
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "from azureml.core import Environment\n",
        "from azureml.core.runconfig import RunConfiguration\n",
        "\n",
        "# Create a Python environment for the experiment (from a .yml file)\n",
        "experiment_env = Environment.from_conda_specification(\"experiment_env\", experiment_folder + \"/experiment_env.yml\")\n",
        "\n",
        "# Register the environment \n",
        "experiment_env.register(workspace=ws)\n",
        "registered_env = Environment.get(ws, 'experiment_env')\n",
        "\n",
        "# Create a new runconfig object for the pipeline\n",
        "pipeline_run_config = RunConfiguration()\n",
        "\n",
        "# Use the compute you created above. \n",
        "pipeline_run_config.target = pipeline_cluster\n",
        "\n",
        "# Assign the environment to the run configuration\n",
        "pipeline_run_config.environment = registered_env\n",
        "\n",
        "print (\"Run configuration created.\")"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "Run configuration created.\n"
        }
      ],
      "execution_count": 8,
      "metadata": {
        "gather": {
          "logged": 1633728461748
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Create and run a pipeline\n",
        "\n",
        "Now you're ready to create and run a pipeline.\n",
        "\n",
        "First you need to define the steps for the pipeline, and any data references that need to be passed between them. In this case, the first step must write the prepared data to a folder that can be read from by the second step. Since the steps will be run on remote compute (and in fact, could each be run on different compute), the folder path must be passed as a data reference to a location in a datastore within the workspace. The **OutputFileDatasetConfig** object is a special kind of data reference that is used for interim storage locations that can be passed between pipeline steps, so you'll create one and use at as the output for the first step and the input for the second step. Note that you need to pass it as a script argument so your code can access the datastore location referenced by the data reference."
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "from azureml.data import OutputFileDatasetConfig\n",
        "from azureml.pipeline.steps import PythonScriptStep\n",
        "\n",
        "# Get the training dataset\n",
        "diabetes_ds = ws.datasets.get(\"diabetes dataset\")\n",
        "\n",
        "# Create an OutputFileDatasetConfig (temporary Data Reference) for data passed from step 1 to step 2\n",
        "prepped_data = OutputFileDatasetConfig(\"prepped_data\")\n",
        "\n",
        "# Step 1, Run the data prep script\n",
        "prep_step = PythonScriptStep(name = \"Prepare Data\",\n",
        "                                source_directory = experiment_folder,\n",
        "                                script_name = \"prep_diabetes.py\",\n",
        "                                arguments = ['--input-data', diabetes_ds.as_named_input('raw_data'),\n",
        "                                             '--prepped-data', prepped_data],\n",
        "                                compute_target = pipeline_cluster,\n",
        "                                runconfig = pipeline_run_config,\n",
        "                                allow_reuse = True)\n",
        "\n",
        "# Step 2, run the training script\n",
        "train_step = PythonScriptStep(name = \"Train and Register Model\",\n",
        "                                source_directory = experiment_folder,\n",
        "                                script_name = \"train_diabetes.py\",\n",
        "                                arguments = ['--training-data', prepped_data.as_input()],\n",
        "                                compute_target = pipeline_cluster,\n",
        "                                runconfig = pipeline_run_config,\n",
        "                                allow_reuse = True)\n",
        "\n",
        "print(\"Pipeline steps defined\")"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "Pipeline steps defined\n"
        }
      ],
      "execution_count": 9,
      "metadata": {
        "gather": {
          "logged": 1633729203605
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "OK, you're ready build the pipeline from the steps you've defined and run it as an experiment."
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "from azureml.core import Experiment\n",
        "from azureml.pipeline.core import Pipeline\n",
        "from azureml.widgets import RunDetails\n",
        "\n",
        "# Construct the pipeline\n",
        "pipeline_steps = [prep_step, train_step]\n",
        "pipeline = Pipeline(workspace=ws, steps=pipeline_steps)\n",
        "print(\"Pipeline is built.\")\n",
        "\n",
        "# Create an experiment and run the pipeline\n",
        "experiment = Experiment(workspace=ws, name = 'mslearn-diabetes-pipeline')\n",
        "pipeline_run = experiment.submit(pipeline, regenerate_outputs=True)\n",
        "print(\"Pipeline submitted for execution.\")\n",
        "RunDetails(pipeline_run).show()\n",
        "pipeline_run.wait_for_completion(show_output=True)"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "Pipeline is built.\nCreated step Prepare Data [70704b25][b72b0236-4416-426f-a23f-0e5aa1bbb66e], (This step will run and generate new outputs)Created step Train and Register Model [987c0531][7cd18df2-77ac-4ff6-a845-dcdcb8ea291e], (This step will run and generate new outputs)\n\nSubmitted PipelineRun 85184152-a15c-4922-9a90-9754e817a35a\nLink to Azure Machine Learning Portal: https://ml.azure.com/runs/85184152-a15c-4922-9a90-9754e817a35a?wsid=/subscriptions/448781ce-ecdd-4bf3-91e9-5674666ebec1/resourcegroups/ict-915-02-jmdl/workspaces/ict-915-02-jmdl&tid=669832bc-1c49-401d-84ca-5fe95035ead2\nPipeline submitted for execution.\nPipelineRunId: 85184152-a15c-4922-9a90-9754e817a35a\nLink to Azure Machine Learning Portal: https://ml.azure.com/runs/85184152-a15c-4922-9a90-9754e817a35a?wsid=/subscriptions/448781ce-ecdd-4bf3-91e9-5674666ebec1/resourcegroups/ict-915-02-jmdl/workspaces/ict-915-02-jmdl&tid=669832bc-1c49-401d-84ca-5fe95035ead2\nPipelineRun Status: NotStarted\n"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": "_PipelineWidget(widget_settings={'childWidgetDisplay': 'popup', 'send_telemetry': False, 'log_level': 'INFO', â€¦",
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "25ce297d873649c9b5be96d806f2d8a3"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "application/aml.mini.widget.v1": "{\"status\": \"Completed\", \"workbench_run_details_uri\": \"https://ml.azure.com/runs/85184152-a15c-4922-9a90-9754e817a35a?wsid=/subscriptions/448781ce-ecdd-4bf3-91e9-5674666ebec1/resourcegroups/ict-915-02-jmdl/workspaces/ict-915-02-jmdl&tid=669832bc-1c49-401d-84ca-5fe95035ead2\", \"run_id\": \"85184152-a15c-4922-9a90-9754e817a35a\", \"run_properties\": {\"run_id\": \"85184152-a15c-4922-9a90-9754e817a35a\", \"created_utc\": \"2021-10-08T21:42:20.688392Z\", \"properties\": {\"azureml.runsource\": \"azureml.PipelineRun\", \"runSource\": \"SDK\", \"runType\": \"SDK\", \"azureml.parameters\": \"{}\", \"azureml.pipelineComponent\": \"pipelinerun\"}, \"tags\": {\"azureml.pipelineComponent\": \"pipelinerun\"}, \"end_time_utc\": \"2021-10-08T21:48:07.49659Z\", \"status\": \"Completed\", \"log_files\": {\"logs/azureml/executionlogs.txt\": \"https://ict91502jmdl5971809827.blob.core.windows.net/azureml/ExperimentRun/dcid.85184152-a15c-4922-9a90-9754e817a35a/logs/azureml/executionlogs.txt?sv=2019-07-07&sr=b&sig=nHPozAhIF9fJWffV2atTd67l520GKuJR%2FmZtFhZ5ZxA%3D&skoid=65509533-6487-43e3-a9e5-9135310d21ed&sktid=669832bc-1c49-401d-84ca-5fe95035ead2&skt=2021-10-08T20%3A51%3A03Z&ske=2021-10-10T05%3A01%3A03Z&sks=b&skv=2019-07-07&st=2021-10-08T21%3A32%3A46Z&se=2021-10-09T05%3A42%3A46Z&sp=r\", \"logs/azureml/stderrlogs.txt\": \"https://ict91502jmdl5971809827.blob.core.windows.net/azureml/ExperimentRun/dcid.85184152-a15c-4922-9a90-9754e817a35a/logs/azureml/stderrlogs.txt?sv=2019-07-07&sr=b&sig=nHAPIFi0ujeMWKZqdFdWeE3GPOcjuhe%2BvuZ9oLVqTtk%3D&skoid=65509533-6487-43e3-a9e5-9135310d21ed&sktid=669832bc-1c49-401d-84ca-5fe95035ead2&skt=2021-10-08T20%3A51%3A03Z&ske=2021-10-10T05%3A01%3A03Z&sks=b&skv=2019-07-07&st=2021-10-08T21%3A32%3A46Z&se=2021-10-09T05%3A42%3A46Z&sp=r\", \"logs/azureml/stdoutlogs.txt\": \"https://ict91502jmdl5971809827.blob.core.windows.net/azureml/ExperimentRun/dcid.85184152-a15c-4922-9a90-9754e817a35a/logs/azureml/stdoutlogs.txt?sv=2019-07-07&sr=b&sig=H6MmNkcSmt%2BJu2AAc7PPXYEXDlXf26OLa4K%2FsXY6DnU%3D&skoid=65509533-6487-43e3-a9e5-9135310d21ed&sktid=669832bc-1c49-401d-84ca-5fe95035ead2&skt=2021-10-08T20%3A51%3A03Z&ske=2021-10-10T05%3A01%3A03Z&sks=b&skv=2019-07-07&st=2021-10-08T21%3A32%3A46Z&se=2021-10-09T05%3A42%3A46Z&sp=r\"}, \"log_groups\": [[\"logs/azureml/executionlogs.txt\", \"logs/azureml/stderrlogs.txt\", \"logs/azureml/stdoutlogs.txt\"]], \"run_duration\": \"0:05:46\", \"run_number\": \"1\", \"run_queued_details\": {\"status\": \"Finished\", \"details\": null}}, \"child_runs\": [{\"run_id\": \"d21e88c3-1251-4791-a6e5-4c38a9d4f64c\", \"name\": \"Prepare Data\", \"status\": \"Finished\", \"start_time\": \"2021-10-08T21:45:08.964987Z\", \"created_time\": \"2021-10-08T21:42:23.599531Z\", \"end_time\": \"2021-10-08T21:47:13.583159Z\", \"duration\": \"0:04:49\", \"run_number\": 2, \"metric\": null, \"run_type\": \"azureml.StepRun\", \"training_percent\": null, \"created_time_dt\": \"2021-10-08T21:42:23.599531Z\", \"is_reused\": \"\"}, {\"run_id\": \"9dc875a6-0c0b-48da-84d6-f6d103842640\", \"name\": \"Train and Register Model\", \"status\": \"Finished\", \"start_time\": \"2021-10-08T21:47:27.712438Z\", \"created_time\": \"2021-10-08T21:47:15.169265Z\", \"end_time\": \"2021-10-08T21:48:06.01897Z\", \"duration\": \"0:00:50\", \"run_number\": 3, \"metric\": null, \"run_type\": \"azureml.StepRun\", \"training_percent\": null, \"created_time_dt\": \"2021-10-08T21:47:15.169265Z\", \"is_reused\": \"\"}], \"children_metrics\": {\"categories\": null, \"series\": null, \"metricName\": null}, \"run_metrics\": [], \"run_logs\": \"[2021-10-08 21:42:23Z] Submitting 1 runs, first five are: 70704b25:d21e88c3-1251-4791-a6e5-4c38a9d4f64c\\n[2021-10-08 21:47:14Z] Completing processing run id d21e88c3-1251-4791-a6e5-4c38a9d4f64c.\\n[2021-10-08 21:47:15Z] Submitting 1 runs, first five are: 987c0531:9dc875a6-0c0b-48da-84d6-f6d103842640\\n[2021-10-08 21:48:07Z] Completing processing run id 9dc875a6-0c0b-48da-84d6-f6d103842640.\\n\\nRun is completed.\", \"graph\": {\"datasource_nodes\": {\"a475e700\": {\"node_id\": \"a475e700\", \"name\": \"diabetes dataset\"}}, \"module_nodes\": {\"70704b25\": {\"node_id\": \"70704b25\", \"name\": \"Prepare Data\", \"status\": \"Finished\", \"_is_reused\": false, \"run_id\": \"d21e88c3-1251-4791-a6e5-4c38a9d4f64c\"}, \"987c0531\": {\"node_id\": \"987c0531\", \"name\": \"Train and Register Model\", \"status\": \"Finished\", \"_is_reused\": false, \"run_id\": \"9dc875a6-0c0b-48da-84d6-f6d103842640\"}}, \"edges\": [{\"source_node_id\": \"a475e700\", \"source_node_name\": \"diabetes dataset\", \"source_name\": \"data\", \"target_name\": \"raw_data\", \"dst_node_id\": \"70704b25\", \"dst_node_name\": \"Prepare Data\"}, {\"source_node_id\": \"70704b25\", \"source_node_name\": \"Prepare Data\", \"source_name\": \"prepped_data\", \"target_name\": \"input_15c2723e\", \"dst_node_id\": \"987c0531\", \"dst_node_name\": \"Train and Register Model\"}], \"child_runs\": [{\"run_id\": \"d21e88c3-1251-4791-a6e5-4c38a9d4f64c\", \"name\": \"Prepare Data\", \"status\": \"Finished\", \"start_time\": \"2021-10-08T21:45:08.964987Z\", \"created_time\": \"2021-10-08T21:42:23.599531Z\", \"end_time\": \"2021-10-08T21:47:13.583159Z\", \"duration\": \"0:04:49\", \"run_number\": 2, \"metric\": null, \"run_type\": \"azureml.StepRun\", \"training_percent\": null, \"created_time_dt\": \"2021-10-08T21:42:23.599531Z\", \"is_reused\": \"\"}, {\"run_id\": \"9dc875a6-0c0b-48da-84d6-f6d103842640\", \"name\": \"Train and Register Model\", \"status\": \"Finished\", \"start_time\": \"2021-10-08T21:47:27.712438Z\", \"created_time\": \"2021-10-08T21:47:15.169265Z\", \"end_time\": \"2021-10-08T21:48:06.01897Z\", \"duration\": \"0:00:50\", \"run_number\": 3, \"metric\": null, \"run_type\": \"azureml.StepRun\", \"training_percent\": null, \"created_time_dt\": \"2021-10-08T21:47:15.169265Z\", \"is_reused\": \"\"}]}, \"widget_settings\": {\"childWidgetDisplay\": \"popup\", \"send_telemetry\": false, \"log_level\": \"INFO\", \"sdk_version\": \"1.34.0\"}, \"loading\": false}"
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "PipelineRun Status: Running\n\n\nStepRunId: d21e88c3-1251-4791-a6e5-4c38a9d4f64c\nLink to Azure Machine Learning Portal: https://ml.azure.com/runs/d21e88c3-1251-4791-a6e5-4c38a9d4f64c?wsid=/subscriptions/448781ce-ecdd-4bf3-91e9-5674666ebec1/resourcegroups/ict-915-02-jmdl/workspaces/ict-915-02-jmdl&tid=669832bc-1c49-401d-84ca-5fe95035ead2\nStepRun( Prepare Data ) Status: Running\n\nStreaming azureml-logs/55_azureml-execution-tvmps_e1613ff6135641c2a128b0ffb7f6b5266031aeab8c73b5f1d1e07eed6cfba49d_d.txt\n========================================================================================================================\n2021-10-08T21:45:09Z Running following command: /bin/bash -c sudo blobfuse /mnt/batch/tasks/shared/LS_root/jobs/ict-915-02-jmdl/azureml/d21e88c3-1251-4791-a6e5-4c38a9d4f64c/mounts/workspaceblobstore --tmp-path=/mnt/batch/tasks/shared/LS_root/jobs/ict-915-02-jmdl/azureml/d21e88c3-1251-4791-a6e5-4c38a9d4f64c/caches/workspaceblobstore -o ro --file-cache-timeout-in-seconds=1000000 --cache-size-mb=24782 -o nonempty -o allow_other --config-file=/mnt/batch/tasks/shared/LS_root/jobs/ict-915-02-jmdl/azureml/d21e88c3-1251-4791-a6e5-4c38a9d4f64c/configs/workspaceblobstore.cfg --log-level=LOG_WARNING\n2021-10-08T21:45:09Z Successfully mounted a/an Blobfuse File System at /mnt/batch/tasks/shared/LS_root/jobs/ict-915-02-jmdl/azureml/d21e88c3-1251-4791-a6e5-4c38a9d4f64c/mounts/workspaceblobstore\n2021-10-08T21:45:09Z The vmsize standard_ds11_v2 is not a GPU VM, skipping get GPU count by running nvidia-smi command.\n2021-10-08T21:45:09Z Starting output-watcher...\n2021-10-08T21:45:10Z IsDedicatedCompute == True, won't poll for Low Pri Preemption\n2021-10-08T21:45:10Z Executing 'Copy ACR Details file' on 10.0.0.4\n2021-10-08T21:45:10Z Copy ACR Details file succeeded on 10.0.0.4. Output: \n>>>   \n>>>   \nLogin Succeeded\nUsing default tag: latest\nlatest: Pulling from azureml/azureml_30c8b4102ff1b91d5efbf92a55b8441f\n92473f7ef455: Pulling fs layer\nfb52bde70123: Pulling fs layer\n64788f86be3f: Pulling fs layer\n33f6d5f2e001: Pulling fs layer\neeb715f1b6ae: Pulling fs layer\nfe519cf36537: Pulling fs layer\n58ff99196c15: Pulling fs layer\n9b13f06a8eff: Pulling fs layer\n2d4e93adbf58: Pulling fs layer\n6ee7c3767844: Pulling fs layer\n62cfc3ccb8ab: Pulling fs layer\n4a7af9d757ee: Pulling fs layer\n2d4a7041ee64: Pulling fs layer\n9b5c830079c4: Pulling fs layer\n339038bcce95: Pulling fs layer\nc691bda31596: Pulling fs layer\n5050e24af0d7: Pulling fs layer\n87ce02e9f0c4: Pulling fs layer\n33f6d5f2e001: Waiting\neeb715f1b6ae: Waiting\nfe519cf36537: Waiting\n58ff99196c15: Waiting\n9b13f06a8eff: Waiting\n2d4e93adbf58: Waiting\n6ee7c3767844: Waiting\n62cfc3ccb8ab: Waiting\n4a7af9d757ee: Waiting\n2d4a7041ee64: Waiting\n9b5c830079c4: Waiting\n339038bcce95: Waiting\nc691bda31596: Waiting\n5050e24af0d7: Waiting\n87ce02e9f0c4: Waiting\n64788f86be3f: Verifying Checksum\n64788f86be3f: Download complete\nfb52bde70123: Verifying Checksum\nfb52bde70123: Download complete\n33f6d5f2e001: Verifying Checksum\n33f6d5f2e001: Download complete\n92473f7ef455: Verifying Checksum\n92473f7ef455: Download complete\nfe519cf36537: Verifying Checksum\nfe519cf36537: Download complete\n58ff99196c15: Verifying Checksum\n58ff99196c15: Download complete\n9b13f06a8eff: Verifying Checksum\n9b13f06a8eff: Download complete\neeb715f1b6ae: Verifying Checksum\neeb715f1b6ae: Download complete\n62cfc3ccb8ab: Verifying Checksum\n62cfc3ccb8ab: Download complete\n4a7af9d757ee: Verifying Checksum\n4a7af9d757ee: Download complete\n6ee7c3767844: Verifying Checksum\n6ee7c3767844: Download complete\n2d4a7041ee64: Verifying Checksum\n2d4a7041ee64: Download complete\n2d4e93adbf58: Verifying Checksum\n2d4e93adbf58: Download complete\n339038bcce95: Verifying Checksum\n339038bcce95: Download complete\nc691bda31596: Verifying Checksum\nc691bda31596: Download complete\n5050e24af0d7: Verifying Checksum\n5050e24af0d7: Download complete\n87ce02e9f0c4: Verifying Checksum\n87ce02e9f0c4: Download complete\n92473f7ef455: Pull complete\n9b5c830079c4: Verifying Checksum\n9b5c830079c4: Download complete\nfb52bde70123: Pull complete\n64788f86be3f: Pull complete\n33f6d5f2e001: Pull complete\neeb715f1b6ae: Pull complete\nfe519cf36537: Pull complete\n58ff99196c15: Pull complete\n9b13f06a8eff: Pull complete\n2d4e93adbf58: Pull complete\n6ee7c3767844: Pull complete\n62cfc3ccb8ab: Pull complete\n4a7af9d757ee: Pull complete\n2d4a7041ee64: Pull complete\n9b5c830079c4: Pull complete\n339038bcce95: Pull complete\nc691bda31596: Pull complete\n5050e24af0d7: Pull complete\n87ce02e9f0c4: Pull complete\nDigest: sha256:ebba444591b1e23c159b5a960c7b0236ca766b90ad7c79e1b4b9731a8a4845e4\nStatus: Downloaded newer image for viennaglobal.azurecr.io/azureml/azureml_30c8b4102ff1b91d5efbf92a55b8441f:latest\nviennaglobal.azurecr.io/azureml/azureml_30c8b4102ff1b91d5efbf92a55b8441f:latest\n2021-10-08T21:45:36Z The vmsize standard_ds11_v2 is not a GPU VM, skipping get GPU count by running nvidia-smi command.\n2021-10-08T21:45:36Z Check if container d21e88c3-1251-4791-a6e5-4c38a9d4f64c_DataSidecar already exist exited with 0, \n\n1f074421e39ad203ce457fd792ce70467d47c66eca42610ab4d3cca56314979a\n2021-10-08T21:45:40Z Parameters for containerSetup task: useDetonationChamer set to false and sshRequired set to false \n2021-10-08T21:45:40Z containerSetup task cmd: [/mnt/batch/tasks/startup/wd/hosttools -task=containerSetup -traceContext=00-ca24efeab66760cc751ba12dc9128b0e-4ad143ed59028886-01 -sshRequired=false] \n2021/10/08 21:45:40 Got JobInfoJson from env\n2021/10/08 21:45:40 Starting App Insight Logger for task:  containerSetup\n2021/10/08 21:45:40 Version: 3.0.01734.0003 Branch: .SourceBranch Commit: 21dafbb\n2021/10/08 21:45:40 Entered ContainerSetupTask - Preparing infiniband\n2021/10/08 21:45:40 Starting infiniband setup\n2021/10/08 21:45:40 Python Version found is Python 3.7.9\n\n2021/10/08 21:45:40 Returning Python Version as 3.7\n2021/10/08 21:45:40 VMSize: standard_ds11_v2, Host: runtime-gen1-ubuntu18, Container: ubuntu-16.04\n2021/10/08 21:45:40 VMSize: standard_ds11_v2, Host: runtime-gen1-ubuntu18, Container: ubuntu-16.04\n2021-10-08T21:45:40Z VMSize: standard_ds11_v2, Host: runtime-gen1-ubuntu18, Container: ubuntu-16.04\n2021/10/08 21:45:40 /dev/infiniband/uverbs0 found (implying presence of InfiniBand)?: false\n2021/10/08 21:45:40 Not setting up Infiniband in Container\n2021/10/08 21:45:40 Not setting up Infiniband in Container\n2021-10-08T21:45:40Z Not setting up Infiniband in Container\n2021/10/08 21:45:40 Python Version found is Python 3.7.9\n\n2021/10/08 21:45:40 Returning Python Version as 3.7\n2021/10/08 21:45:40 sshd inside container not required for job, skipping setup.\n2021/10/08 21:45:40 All App Insights Logs was sent successfully or the close timeout of 10 was reached\n2021/10/08 21:45:40 App Insight Client has already been closed\n2021/10/08 21:45:40 Not exporting to RunHistory as the exporter is either stopped or there is no data.\nStopped: false\nOriginalData: 1\nFilteredData: 0.\n2021-10-08T21:45:40Z Starting docker container succeeded.\n2021-10-08T21:45:40Z The vmsize standard_ds11_v2 is not a GPU VM, skipping get GPU count by running nvidia-smi command.\n2021-10-08T21:45:54Z The vmsize standard_ds11_v2 is not a GPU VM, skipping get GPU count by running nvidia-smi command.\n2021-10-08T21:45:54Z The vmsize standard_ds11_v2 is not a GPU VM, skipping get GPU count by running nvidia-smi command.\n2021-10-08T21:45:54Z Executing 'Copy ACR Details file' on 10.0.0.4\n2021-10-08T21:45:54Z Copy ACR Details file succeeded on 10.0.0.4. Output: \n>>>   \n>>>   \nLogin Succeeded\nUsing default tag: latest\nlatest: Pulling from azureml/azureml_21ec214220b650a356d20fde58334d25\nfeac53061382: Pulling fs layer\n7dce5c8175d6: Pulling fs layer\n0a1b9502ed8f: Pulling fs layer\nd187f505e8b8: Pulling fs layer\nc7a3c00b133d: Pulling fs layer\n31b816123763: Pulling fs layer\n37b899c2505c: Pulling fs layer\nabda0175e0e2: Pulling fs layer\n19d6148ce542: Pulling fs layer\nb4108a58b79a: Pulling fs layer\nf8ebb86cf83a: Pulling fs layer\nf5390c98104e: Pulling fs layer\nc311d79514a5: Pulling fs layer\n1d4cf2dd4121: Pulling fs layer\n7381a3ce053b: Pulling fs layer\nb05a60c0d39c: Pulling fs layer\n3ca6be995cad: Pulling fs layer\na3b9cea4d6c6: Pulling fs layer\nb4108a58b79a: Waiting\nf8ebb86cf83a: Waiting\nf5390c98104e: Waiting\nc311d79514a5: Waiting\n1d4cf2dd4121: Waiting\n7381a3ce053b: Waiting\nb05a60c0d39c: Waiting\n3ca6be995cad: Waiting\na3b9cea4d6c6: Waiting\nd187f505e8b8: Waiting\n37b899c2505c: Waiting\nabda0175e0e2: Waiting\n19d6148ce542: Waiting\nc7a3c00b133d: Waiting\n31b816123763: Waiting\n0a1b9502ed8f: Verifying Checksum\n0a1b9502ed8f: Download complete\n\nStreaming azureml-logs/65_job_prep-tvmps_e1613ff6135641c2a128b0ffb7f6b5266031aeab8c73b5f1d1e07eed6cfba49d_d.txt\n===============================================================================================================\n[2021-10-08T21:45:43.049118] Entering job preparation.\n[2021-10-08T21:45:43.802954] Starting job preparation.\n[2021-10-08T21:45:43.802992] Extracting the control code.\n[2021-10-08T21:45:43.803442] Starting extract_project.\n[2021-10-08T21:45:43.803519] Starting to extract zip file.\n[2021-10-08T21:45:43.848845] Finished extracting zip file.\n[2021-10-08T21:45:43.852382] Using urllib.request Python 3.0 or later\n[2021-10-08T21:45:43.852467] Start fetching snapshots.\n[2021-10-08T21:45:43.852526] Start fetching snapshot.\n[2021-10-08T21:45:43.852606] Retrieving project from snapshot: 12c67a3e-2174-4906-97de-c1712432976e\nStarting the daemon thread to refresh tokens in background for process with pid = 50\n[2021-10-08T21:45:44.175256] Finished fetching snapshot.\n[2021-10-08T21:45:44.175290] Finished fetching snapshots.\n[2021-10-08T21:45:44.175300] Finished extract_project.\n[2021-10-08T21:45:44.175651] Finished fetching and extracting the control code.\n[2021-10-08T21:45:44.184332] Start run_history_prep.\n[2021-10-08T21:45:44.191505] Job preparation is complete.\n[2021-10-08T21:45:44.191676] Entering Data Context Managers in Sidecar\n[2021-10-08T21:45:44.192578] Running Sidecar prep cmd...\n[2021-10-08T21:45:44.623878] INFO azureml.sidecar.sidecar: Received task: enter_contexts. Running on Linux at /mnt/hostfs/mnt/batch/tasks/shared/LS_root/jobs/ict-915-02-jmdl/azureml/d21e88c3-1251-4791-a6e5-4c38a9d4f64c/wd/azureml/d21e88c3-1251-4791-a6e5-4c38a9d4f64c\n[2021-10-08T21:45:44.624751] INFO azureml.sidecar.sidecar: Invoking \"enter_contexts\" task with Context Managers: {\"context_managers\": [\"Dataset:context_managers.Datasets\"]}\n[2021-10-08T21:45:44.832] Enter __enter__ of DatasetContextManager\n[2021-10-08T21:45:44.834] SDK version: azureml-core==1.33.0.post1 azureml-dataprep==2.22.2. Session id: 43a7d428-ce2b-46e9-9722-ff60d7991108. Run id: d21e88c3-1251-4791-a6e5-4c38a9d4f64c.\n[2021-10-08T21:45:44.834] Processing 'prepped_data'.\n[2021-10-08T21:45:44.834] Mode: 'mount'.\n[2021-10-08T21:45:44.834] Path on compute is specified: '/mnt/hostfs/mnt/batch/tasks/shared/LS_root/jobs/ict-915-02-jmdl/azureml/d21e88c3-1251-4791-a6e5-4c38a9d4f64c/wd/prepped_data_workspaceblobstore'.\n[2021-10-08T21:45:48.451] Mounting prepped_data to /mnt/hostfs/mnt/batch/tasks/shared/LS_root/jobs/ict-915-02-jmdl/azureml/d21e88c3-1251-4791-a6e5-4c38a9d4f64c/wd/prepped_data_workspaceblobstore.\n[2021-10-08T21:45:53.502] Mounted prepped_data to /mnt/hostfs/mnt/batch/tasks/shared/LS_root/jobs/ict-915-02-jmdl/azureml/d21e88c3-1251-4791-a6e5-4c38a9d4f64c/wd/prepped_data_workspaceblobstore.\n[2021-10-08T21:45:53.569] Exit __enter__ of DatasetContextManager\nSet OutputDataset prepped_data's target path to /mnt/batch/tasks/shared/LS_root/jobs/ict-915-02-jmdl/azureml/d21e88c3-1251-4791-a6e5-4c38a9d4f64c/wd/prepped_data_workspaceblobstore\n[2021-10-08T21:45:53.570365] INFO azureml.sidecar.task.enter_contexts: Entered Context Managers\n[2021-10-08T21:45:53.890801] Ran Sidecar prep cmd.\n[2021-10-08T21:45:53.890881] Running Context Managers in Sidecar complete.\n\nStreaming azureml-logs/75_job_post-tvmps_e1613ff6135641c2a128b0ffb7f6b5266031aeab8c73b5f1d1e07eed6cfba49d_d.txt\n===============================================================================================================\n[2021-10-08T21:47:03.360656] Entering job release\n[2021-10-08T21:47:04.273120] Starting job release\n[2021-10-08T21:47:04.273957] Logging experiment finalizing status in history service.\nStarting the daemon thread to refresh tokens in background for process with pid = 234\n[2021-10-08T21:47:04.274567] job release stage : upload_datastore starting...\n[2021-10-08T21:47:04.290282] Entering context manager injector.\n[2021-10-08T21:47:04.293042] job release stage : start importing azureml.history._tracking in run_history_release.\n[2021-10-08T21:47:04.293352] job release stage : execute_job_release starting...\n[2021-10-08T21:47:04.294425] job release stage : upload_datastore completed...\n[2021-10-08T21:47:04.297730] job release stage : copy_batchai_cached_logs starting...\n[2021-10-08T21:47:04.298986] job release stage : copy_batchai_cached_logs completed...\n[2021-10-08T21:47:04.364635] job release stage : send_run_telemetry starting...\n[2021-10-08T21:47:04.390933] get vm size and vm region successfully.\n[2021-10-08T21:47:04.403794] get compute meta data successfully.\n[2021-10-08T21:47:04.530149] job release stage : execute_job_release completed...\n[2021-10-08T21:47:04.658774] post artifact meta request successfully.\n[2021-10-08T21:47:04.702088] upload compute record artifact successfully.\n[2021-10-08T21:47:04.702171] job release stage : send_run_telemetry completed...\n[2021-10-08T21:47:04.702595] Running in AzureML-Sidecar, starting to exit user context managers...\n[2021-10-08T21:47:04.702700] Running Sidecar release cmd...\n[2021-10-08T21:47:04.715181] INFO azureml.sidecar.sidecar: Received task: exit_contexts. Running on Linux at /mnt/hostfs/mnt/batch/tasks/shared/LS_root/jobs/ict-915-02-jmdl/azureml/d21e88c3-1251-4791-a6e5-4c38a9d4f64c/wd/azureml/d21e88c3-1251-4791-a6e5-4c38a9d4f64c\n[2021-10-08T21:47:04.735] Enter __exit__ of DatasetContextManager\n[2021-10-08T21:47:04.735] Unmounting /mnt/hostfs/mnt/batch/tasks/shared/LS_root/jobs/ict-915-02-jmdl/azureml/d21e88c3-1251-4791-a6e5-4c38a9d4f64c/wd/prepped_data_workspaceblobstore.\n[2021-10-08T21:47:04.759] Finishing unmounting /mnt/hostfs/mnt/batch/tasks/shared/LS_root/jobs/ict-915-02-jmdl/azureml/d21e88c3-1251-4791-a6e5-4c38a9d4f64c/wd/prepped_data_workspaceblobstore.\n[2021-10-08T21:47:04.759] Exit __exit__ of DatasetContextManager\n[2021-10-08T21:47:04.759398] Removing absolute paths from host...\n[2021-10-08T21:47:04.759713] INFO azureml.sidecar.task.exit_contexts: Exited Context Managers\n[2021-10-08T21:47:05.424929] Ran Sidecar release cmd.\n[2021-10-08T21:47:05.425028] Job release is complete\n\nStepRun(Prepare Data) Execution Summary\n========================================\nStepRun( Prepare Data ) Status: Finished\n{'runId': 'd21e88c3-1251-4791-a6e5-4c38a9d4f64c', 'target': 'CT-915-02-JMDL', 'status': 'Completed', 'startTimeUtc': '2021-10-08T21:45:08.964987Z', 'endTimeUtc': '2021-10-08T21:47:13.583159Z', 'services': {}, 'properties': {'ContentSnapshotId': '12c67a3e-2174-4906-97de-c1712432976e', 'StepType': 'PythonScriptStep', 'ComputeTargetType': 'AmlCompute', 'azureml.moduleid': 'b72b0236-4416-426f-a23f-0e5aa1bbb66e', 'azureml.runsource': 'azureml.StepRun', 'azureml.nodeid': '70704b25', 'azureml.pipelinerunid': '85184152-a15c-4922-9a90-9754e817a35a', 'azureml.pipeline': '85184152-a15c-4922-9a90-9754e817a35a', 'azureml.pipelineComponent': 'masterescloud', '_azureml.ComputeTargetType': 'amlcompute', 'ProcessInfoFile': 'azureml-logs/process_info.json', 'ProcessStatusFile': 'azureml-logs/process_status.json'}, 'inputDatasets': [{'dataset': {'id': '0c4a8599-44a0-4e8d-a52b-b00626653fbd'}, 'consumptionDetails': {'type': 'RunInput', 'inputName': 'raw_data', 'mechanism': 'Direct'}}], 'outputDatasets': [{'identifier': {'savedId': 'b60ed111-8436-4f01-b722-3ec17812b6d6'}, 'outputType': 'RunOutput', 'outputDetails': {'outputName': 'prepped_data'}, 'dataset': {\n  \"source\": [\n    \"('workspaceblobstore', 'dataset/d21e88c3-1251-4791-a6e5-4c38a9d4f64c/prepped_data/')\"\n  ],\n  \"definition\": [\n    \"GetDatastoreFiles\"\n  ],\n  \"registration\": {\n    \"id\": \"b60ed111-8436-4f01-b722-3ec17812b6d6\",\n    \"name\": null,\n    \"version\": null,\n    \"workspace\": \"Workspace.create(name='ict-915-02-jmdl', subscription_id='448781ce-ecdd-4bf3-91e9-5674666ebec1', resource_group='ict-915-02-jmdl')\"\n  }\n}}], 'runDefinition': {'script': 'prep_diabetes.py', 'command': '', 'useAbsolutePath': False, 'arguments': ['--input-data', 'DatasetConsumptionConfig:raw_data', '--prepped-data', 'DatasetOutputConfig:prepped_data'], 'sourceDirectoryDataStore': None, 'framework': 'Python', 'communicator': 'None', 'target': 'CT-915-02-JMDL', 'dataReferences': {}, 'data': {'raw_data': {'dataLocation': {'dataset': {'id': '0c4a8599-44a0-4e8d-a52b-b00626653fbd', 'name': None, 'version': '2'}, 'dataPath': None, 'uri': None}, 'mechanism': 'Direct', 'environmentVariableName': 'raw_data', 'pathOnCompute': None, 'overwrite': False, 'options': None}}, 'outputData': {'prepped_data': {'outputLocation': {'dataset': None, 'dataPath': {'datastoreName': 'workspaceblobstore', 'relativePath': None}, 'uri': None}, 'mechanism': 'Mount', 'additionalOptions': {'pathOnCompute': None, 'registrationOptions': {'name': None, 'description': None, 'tags': None, 'datasetRegistrationOptions': {'additionalTransformation': None}}, 'uploadOptions': {'overwrite': False, 'sourceGlobs': {'globPatterns': None}}, 'mountOptions': None}, 'environmentVariableName': None}}, 'datacaches': [], 'jobName': None, 'maxRunDurationSeconds': None, 'nodeCount': 1, 'instanceTypes': [], 'priority': None, 'credentialPassthrough': False, 'identity': None, 'environment': {'name': 'experiment_env', 'version': '1', 'python': {'interpreterPath': 'python', 'userManagedDependencies': False, 'condaDependencies': {'dependencies': ['python=3.6.2', 'scikit-learn', 'ipykernel', 'matplotlib', 'pandas', 'pip', {'pip': ['azureml-defaults', 'pyarrow']}], 'name': 'azureml_0c5a9aa2def4b3c2501c1f40287a356b'}, 'baseCondaEnvironment': None}, 'environmentVariables': {'EXAMPLE_ENV_VAR': 'EXAMPLE_VALUE'}, 'docker': {'baseImage': 'mcr.microsoft.com/azureml/openmpi3.1.2-ubuntu18.04:20210806.v1', 'platform': {'os': 'Linux', 'architecture': 'amd64'}, 'baseDockerfile': None, 'baseImageRegistry': {'address': None, 'username': None, 'password': None}, 'enabled': False, 'arguments': []}, 'spark': {'repositories': [], 'packages': [], 'precachePackages': True}, 'inferencingStackVersion': None}, 'history': {'outputCollection': True, 'directoriesToWatch': ['logs'], 'enableMLflowTracking': True, 'snapshotProject': True}, 'spark': {'configuration': {'spark.app.name': 'Azure ML Experiment', 'spark.yarn.maxAppAttempts': '1'}}, 'parallelTask': {'maxRetriesPerWorker': 0, 'workerCountPerNode': 1, 'terminalExitCodes': None, 'configuration': {}}, 'amlCompute': {'name': None, 'vmSize': None, 'retainCluster': False, 'clusterMaxNodeCount': 1, 'location': None}, 'aiSuperComputer': {'instanceType': 'AISupercomputer.D2', 'imageVersion': 'pytorch-1.7.0', 'location': None, 'aiSuperComputerStorageData': None, 'interactive': False, 'scalePolicy': None, 'virtualClusterArmId': None, 'tensorboardLogDirectory': None, 'sshPublicKey': None, 'enableAzmlInt': True, 'priority': 'Medium', 'slaTier': 'Standard', 'userAlias': None}, 'kubernetesCompute': {'instanceType': None}, 'tensorflow': {'workerCount': 1, 'parameterServerCount': 1}, 'mpi': {'processCountPerNode': 1}, 'pyTorch': {'communicationBackend': 'nccl', 'processCount': None}, 'hdi': {'yarnDeployMode': 'Cluster'}, 'containerInstance': {'region': None, 'cpuCores': 2.0, 'memoryGb': 3.5}, 'exposedPorts': None, 'docker': {'useDocker': False, 'sharedVolumes': True, 'shmSize': '2g', 'arguments': []}, 'cmk8sCompute': {'configuration': {}}, 'commandReturnCodeConfig': {'returnCode': 'Zero', 'successfulReturnCodes': []}, 'environmentVariables': {}, 'applicationEndpoints': {}, 'parameters': [], 'dataBricks': {'workers': 0, 'minimumWorkerCount': 0, 'maxMumWorkerCount': 0, 'sparkVersion': '4.0.x-scala2.11', 'nodeTypeId': 'Standard_D3_v2', 'sparkConf': {}, 'sparkEnvVars': {}, 'instancePoolId': None, 'timeoutSeconds': 0, 'linkedADBWorkspaceMetadata': None, 'databrickResourceId': None}}, 'logFiles': {'azureml-logs/55_azureml-execution-tvmps_e1613ff6135641c2a128b0ffb7f6b5266031aeab8c73b5f1d1e07eed6cfba49d_d.txt': 'https://ict91502jmdl5971809827.blob.core.windows.net/azureml/ExperimentRun/dcid.d21e88c3-1251-4791-a6e5-4c38a9d4f64c/azureml-logs/55_azureml-execution-tvmps_e1613ff6135641c2a128b0ffb7f6b5266031aeab8c73b5f1d1e07eed6cfba49d_d.txt?sv=2019-07-07&sr=b&sig=WPtRzGjJryF%2FuSLjzKupY5yp0OV0i%2FG4O5gr6LlQjLs%3D&skoid=65509533-6487-43e3-a9e5-9135310d21ed&sktid=669832bc-1c49-401d-84ca-5fe95035ead2&skt=2021-10-08T20%3A47%3A07Z&ske=2021-10-10T04%3A57%3A07Z&sks=b&skv=2019-07-07&st=2021-10-08T21%3A37%3A07Z&se=2021-10-09T05%3A47%3A07Z&sp=r', 'azureml-logs/65_job_prep-tvmps_e1613ff6135641c2a128b0ffb7f6b5266031aeab8c73b5f1d1e07eed6cfba49d_d.txt': 'https://ict91502jmdl5971809827.blob.core.windows.net/azureml/ExperimentRun/dcid.d21e88c3-1251-4791-a6e5-4c38a9d4f64c/azureml-logs/65_job_prep-tvmps_e1613ff6135641c2a128b0ffb7f6b5266031aeab8c73b5f1d1e07eed6cfba49d_d.txt?sv=2019-07-07&sr=b&sig=mtouznVDWOvYbya5I9ZYg5t8sbvARoMbuaRMPYAy9Zo%3D&skoid=65509533-6487-43e3-a9e5-9135310d21ed&sktid=669832bc-1c49-401d-84ca-5fe95035ead2&skt=2021-10-08T20%3A47%3A07Z&ske=2021-10-10T04%3A57%3A07Z&sks=b&skv=2019-07-07&st=2021-10-08T21%3A37%3A07Z&se=2021-10-09T05%3A47%3A07Z&sp=r', 'azureml-logs/70_driver_log.txt': 'https://ict91502jmdl5971809827.blob.core.windows.net/azureml/ExperimentRun/dcid.d21e88c3-1251-4791-a6e5-4c38a9d4f64c/azureml-logs/70_driver_log.txt?sv=2019-07-07&sr=b&sig=y5u2AGyQG8nBV8uY0T0PJSIJoqxpXzXYVC9ifktrdnM%3D&skoid=65509533-6487-43e3-a9e5-9135310d21ed&sktid=669832bc-1c49-401d-84ca-5fe95035ead2&skt=2021-10-08T20%3A47%3A07Z&ske=2021-10-10T04%3A57%3A07Z&sks=b&skv=2019-07-07&st=2021-10-08T21%3A37%3A07Z&se=2021-10-09T05%3A47%3A07Z&sp=r', 'azureml-logs/75_job_post-tvmps_e1613ff6135641c2a128b0ffb7f6b5266031aeab8c73b5f1d1e07eed6cfba49d_d.txt': 'https://ict91502jmdl5971809827.blob.core.windows.net/azureml/ExperimentRun/dcid.d21e88c3-1251-4791-a6e5-4c38a9d4f64c/azureml-logs/75_job_post-tvmps_e1613ff6135641c2a128b0ffb7f6b5266031aeab8c73b5f1d1e07eed6cfba49d_d.txt?sv=2019-07-07&sr=b&sig=UoBCymjz6iE21jCTfn0trtdMG%2Fb3Y8aX9x4yOZyIJMk%3D&skoid=65509533-6487-43e3-a9e5-9135310d21ed&sktid=669832bc-1c49-401d-84ca-5fe95035ead2&skt=2021-10-08T20%3A47%3A07Z&ske=2021-10-10T04%3A57%3A07Z&sks=b&skv=2019-07-07&st=2021-10-08T21%3A37%3A07Z&se=2021-10-09T05%3A47%3A07Z&sp=r', 'azureml-logs/process_info.json': 'https://ict91502jmdl5971809827.blob.core.windows.net/azureml/ExperimentRun/dcid.d21e88c3-1251-4791-a6e5-4c38a9d4f64c/azureml-logs/process_info.json?sv=2019-07-07&sr=b&sig=YZA5vLMuakfES3nLX0eXkAYK5ZlI4rB9ZTP1u11aES8%3D&skoid=65509533-6487-43e3-a9e5-9135310d21ed&sktid=669832bc-1c49-401d-84ca-5fe95035ead2&skt=2021-10-08T20%3A47%3A07Z&ske=2021-10-10T04%3A57%3A07Z&sks=b&skv=2019-07-07&st=2021-10-08T21%3A37%3A07Z&se=2021-10-09T05%3A47%3A07Z&sp=r', 'azureml-logs/process_status.json': 'https://ict91502jmdl5971809827.blob.core.windows.net/azureml/ExperimentRun/dcid.d21e88c3-1251-4791-a6e5-4c38a9d4f64c/azureml-logs/process_status.json?sv=2019-07-07&sr=b&sig=0EjZZ1azb45WHjdIb4q4wPeugMxkHYNFLg18Fl0JMJ0%3D&skoid=65509533-6487-43e3-a9e5-9135310d21ed&sktid=669832bc-1c49-401d-84ca-5fe95035ead2&skt=2021-10-08T20%3A47%3A07Z&ske=2021-10-10T04%3A57%3A07Z&sks=b&skv=2019-07-07&st=2021-10-08T21%3A37%3A07Z&se=2021-10-09T05%3A47%3A07Z&sp=r', 'logs/azureml/72_azureml.log': 'https://ict91502jmdl5971809827.blob.core.windows.net/azureml/ExperimentRun/dcid.d21e88c3-1251-4791-a6e5-4c38a9d4f64c/logs/azureml/72_azureml.log?sv=2019-07-07&sr=b&sig=vub7IedUf46FlRIy42Fw%2BtK89zZIGRN1WANlPhA8eFE%3D&skoid=65509533-6487-43e3-a9e5-9135310d21ed&sktid=669832bc-1c49-401d-84ca-5fe95035ead2&skt=2021-10-08T20%3A32%3A47Z&ske=2021-10-10T04%3A42%3A47Z&sks=b&skv=2019-07-07&st=2021-10-08T21%3A37%3A07Z&se=2021-10-09T05%3A47%3A07Z&sp=r', 'logs/azureml/dataprep/backgroundProcess.log': 'https://ict91502jmdl5971809827.blob.core.windows.net/azureml/ExperimentRun/dcid.d21e88c3-1251-4791-a6e5-4c38a9d4f64c/logs/azureml/dataprep/backgroundProcess.log?sv=2019-07-07&sr=b&sig=H8M90nhc8Y7IuiUYl1ZFyvfNMov8jOgdwO22xPAF1dI%3D&skoid=65509533-6487-43e3-a9e5-9135310d21ed&sktid=669832bc-1c49-401d-84ca-5fe95035ead2&skt=2021-10-08T20%3A32%3A47Z&ske=2021-10-10T04%3A42%3A47Z&sks=b&skv=2019-07-07&st=2021-10-08T21%3A37%3A07Z&se=2021-10-09T05%3A47%3A07Z&sp=r', 'logs/azureml/dataprep/backgroundProcess_Telemetry.log': 'https://ict91502jmdl5971809827.blob.core.windows.net/azureml/ExperimentRun/dcid.d21e88c3-1251-4791-a6e5-4c38a9d4f64c/logs/azureml/dataprep/backgroundProcess_Telemetry.log?sv=2019-07-07&sr=b&sig=SuiZ6OSEUS2AMANSAJIvdwFwImqMtb%2B1wNtFpSi%2B0gU%3D&skoid=65509533-6487-43e3-a9e5-9135310d21ed&sktid=669832bc-1c49-401d-84ca-5fe95035ead2&skt=2021-10-08T20%3A32%3A47Z&ske=2021-10-10T04%3A42%3A47Z&sks=b&skv=2019-07-07&st=2021-10-08T21%3A37%3A07Z&se=2021-10-09T05%3A47%3A07Z&sp=r', 'logs/azureml/executionlogs.txt': 'https://ict91502jmdl5971809827.blob.core.windows.net/azureml/ExperimentRun/dcid.d21e88c3-1251-4791-a6e5-4c38a9d4f64c/logs/azureml/executionlogs.txt?sv=2019-07-07&sr=b&sig=j%2BAuF2OdrUrj%2BbYkVPWfrGcBueoYA3rY2fSibi%2BNy8k%3D&skoid=65509533-6487-43e3-a9e5-9135310d21ed&sktid=669832bc-1c49-401d-84ca-5fe95035ead2&skt=2021-10-08T20%3A32%3A47Z&ske=2021-10-10T04%3A42%3A47Z&sks=b&skv=2019-07-07&st=2021-10-08T21%3A37%3A07Z&se=2021-10-09T05%3A47%3A07Z&sp=r', 'logs/azureml/job_prep_azureml.log': 'https://ict91502jmdl5971809827.blob.core.windows.net/azureml/ExperimentRun/dcid.d21e88c3-1251-4791-a6e5-4c38a9d4f64c/logs/azureml/job_prep_azureml.log?sv=2019-07-07&sr=b&sig=4MNG8bTaSD%2FCeVt8E3SVcj88CCc6xBPwXqie4kzQ9QA%3D&skoid=65509533-6487-43e3-a9e5-9135310d21ed&sktid=669832bc-1c49-401d-84ca-5fe95035ead2&skt=2021-10-08T20%3A32%3A47Z&ske=2021-10-10T04%3A42%3A47Z&sks=b&skv=2019-07-07&st=2021-10-08T21%3A37%3A07Z&se=2021-10-09T05%3A47%3A07Z&sp=r', 'logs/azureml/job_release_azureml.log': 'https://ict91502jmdl5971809827.blob.core.windows.net/azureml/ExperimentRun/dcid.d21e88c3-1251-4791-a6e5-4c38a9d4f64c/logs/azureml/job_release_azureml.log?sv=2019-07-07&sr=b&sig=h1wPlY%2BBvFOjEHB8hHOfJM4dLXizSuam8Gs1M8%2F3DKQ%3D&skoid=65509533-6487-43e3-a9e5-9135310d21ed&sktid=669832bc-1c49-401d-84ca-5fe95035ead2&skt=2021-10-08T20%3A32%3A47Z&ske=2021-10-10T04%3A42%3A47Z&sks=b&skv=2019-07-07&st=2021-10-08T21%3A37%3A07Z&se=2021-10-09T05%3A47%3A07Z&sp=r', 'logs/azureml/sidecar/tvmps_e1613ff6135641c2a128b0ffb7f6b5266031aeab8c73b5f1d1e07eed6cfba49d_d/all.log': 'https://ict91502jmdl5971809827.blob.core.windows.net/azureml/ExperimentRun/dcid.d21e88c3-1251-4791-a6e5-4c38a9d4f64c/logs/azureml/sidecar/tvmps_e1613ff6135641c2a128b0ffb7f6b5266031aeab8c73b5f1d1e07eed6cfba49d_d/all.log?sv=2019-07-07&sr=b&sig=2OI4%2BuFl6CbKoRF3%2F77xILdWGmsrTRaWH2%2B4ZpIijjg%3D&skoid=65509533-6487-43e3-a9e5-9135310d21ed&sktid=669832bc-1c49-401d-84ca-5fe95035ead2&skt=2021-10-08T20%3A32%3A47Z&ske=2021-10-10T04%3A42%3A47Z&sks=b&skv=2019-07-07&st=2021-10-08T21%3A37%3A07Z&se=2021-10-09T05%3A47%3A07Z&sp=r', 'logs/azureml/sidecar/tvmps_e1613ff6135641c2a128b0ffb7f6b5266031aeab8c73b5f1d1e07eed6cfba49d_d/task.enter_contexts.log': 'https://ict91502jmdl5971809827.blob.core.windows.net/azureml/ExperimentRun/dcid.d21e88c3-1251-4791-a6e5-4c38a9d4f64c/logs/azureml/sidecar/tvmps_e1613ff6135641c2a128b0ffb7f6b5266031aeab8c73b5f1d1e07eed6cfba49d_d/task.enter_contexts.log?sv=2019-07-07&sr=b&sig=XbJe3Y9LXLNlR2pGCpBufi2%2F8gEKDDeiZkezY1cWiqQ%3D&skoid=65509533-6487-43e3-a9e5-9135310d21ed&sktid=669832bc-1c49-401d-84ca-5fe95035ead2&skt=2021-10-08T20%3A32%3A47Z&ske=2021-10-10T04%3A42%3A47Z&sks=b&skv=2019-07-07&st=2021-10-08T21%3A37%3A07Z&se=2021-10-09T05%3A47%3A07Z&sp=r', 'logs/azureml/sidecar/tvmps_e1613ff6135641c2a128b0ffb7f6b5266031aeab8c73b5f1d1e07eed6cfba49d_d/task.exit_contexts.log': 'https://ict91502jmdl5971809827.blob.core.windows.net/azureml/ExperimentRun/dcid.d21e88c3-1251-4791-a6e5-4c38a9d4f64c/logs/azureml/sidecar/tvmps_e1613ff6135641c2a128b0ffb7f6b5266031aeab8c73b5f1d1e07eed6cfba49d_d/task.exit_contexts.log?sv=2019-07-07&sr=b&sig=lFYXZSsCCoMONaopnW3upgj0ehD6BfZHsjq61tu5ehE%3D&skoid=65509533-6487-43e3-a9e5-9135310d21ed&sktid=669832bc-1c49-401d-84ca-5fe95035ead2&skt=2021-10-08T20%3A32%3A47Z&ske=2021-10-10T04%3A42%3A47Z&sks=b&skv=2019-07-07&st=2021-10-08T21%3A37%3A07Z&se=2021-10-09T05%3A47%3A07Z&sp=r', 'logs/azureml/stderrlogs.txt': 'https://ict91502jmdl5971809827.blob.core.windows.net/azureml/ExperimentRun/dcid.d21e88c3-1251-4791-a6e5-4c38a9d4f64c/logs/azureml/stderrlogs.txt?sv=2019-07-07&sr=b&sig=g6aYeBM29k6STwigDdSH609U319fNo1mtp6bXvRRWwc%3D&skoid=65509533-6487-43e3-a9e5-9135310d21ed&sktid=669832bc-1c49-401d-84ca-5fe95035ead2&skt=2021-10-08T20%3A32%3A47Z&ske=2021-10-10T04%3A42%3A47Z&sks=b&skv=2019-07-07&st=2021-10-08T21%3A37%3A07Z&se=2021-10-09T05%3A47%3A07Z&sp=r', 'logs/azureml/stdoutlogs.txt': 'https://ict91502jmdl5971809827.blob.core.windows.net/azureml/ExperimentRun/dcid.d21e88c3-1251-4791-a6e5-4c38a9d4f64c/logs/azureml/stdoutlogs.txt?sv=2019-07-07&sr=b&sig=nfpTdFJR%2B%2B94N7LIZ6T5WJQ9gjoy0HiCzSsXj1KUIJY%3D&skoid=65509533-6487-43e3-a9e5-9135310d21ed&sktid=669832bc-1c49-401d-84ca-5fe95035ead2&skt=2021-10-08T20%3A32%3A47Z&ske=2021-10-10T04%3A42%3A47Z&sks=b&skv=2019-07-07&st=2021-10-08T21%3A37%3A07Z&se=2021-10-09T05%3A47%3A07Z&sp=r'}, 'submittedBy': 'Francisco Javier Medel Medina'}\n\n\n\n\nStepRunId: 9dc875a6-0c0b-48da-84d6-f6d103842640\nLink to Azure Machine Learning Portal: https://ml.azure.com/runs/9dc875a6-0c0b-48da-84d6-f6d103842640?wsid=/subscriptions/448781ce-ecdd-4bf3-91e9-5674666ebec1/resourcegroups/ict-915-02-jmdl/workspaces/ict-915-02-jmdl&tid=669832bc-1c49-401d-84ca-5fe95035ead2\nStepRun( Train and Register Model ) Status: Running\n\nStreaming azureml-logs/55_azureml-execution-tvmps_e1613ff6135641c2a128b0ffb7f6b5266031aeab8c73b5f1d1e07eed6cfba49d_d.txt\n========================================================================================================================\n2021-10-08T21:47:28Z Running following command: /bin/bash -c sudo blobfuse /mnt/batch/tasks/shared/LS_root/jobs/ict-915-02-jmdl/azureml/9dc875a6-0c0b-48da-84d6-f6d103842640/mounts/workspaceblobstore --tmp-path=/mnt/batch/tasks/shared/LS_root/jobs/ict-915-02-jmdl/azureml/9dc875a6-0c0b-48da-84d6-f6d103842640/caches/workspaceblobstore -o ro --file-cache-timeout-in-seconds=1000000 --cache-size-mb=20284 -o nonempty -o allow_other --config-file=/mnt/batch/tasks/shared/LS_root/jobs/ict-915-02-jmdl/azureml/9dc875a6-0c0b-48da-84d6-f6d103842640/configs/workspaceblobstore.cfg --log-level=LOG_WARNING\n2021-10-08T21:47:28Z Successfully mounted a/an Blobfuse File System at /mnt/batch/tasks/shared/LS_root/jobs/ict-915-02-jmdl/azureml/9dc875a6-0c0b-48da-84d6-f6d103842640/mounts/workspaceblobstore\n2021-10-08T21:47:29Z The vmsize standard_ds11_v2 is not a GPU VM, skipping get GPU count by running nvidia-smi command.\n2021-10-08T21:47:29Z Starting output-watcher...\n2021-10-08T21:47:29Z IsDedicatedCompute == True, won't poll for Low Pri Preemption\n2021-10-08T21:47:29Z Executing 'Copy ACR Details file' on 10.0.0.4\n2021-10-08T21:47:29Z Copy ACR Details file succeeded on 10.0.0.4. Output: \n>>>   \n>>>   \nLogin Succeeded\nUsing default tag: latest\nlatest: Pulling from azureml/azureml_30c8b4102ff1b91d5efbf92a55b8441f\nDigest: sha256:ebba444591b1e23c159b5a960c7b0236ca766b90ad7c79e1b4b9731a8a4845e4\nStatus: Image is up to date for viennaglobal.azurecr.io/azureml/azureml_30c8b4102ff1b91d5efbf92a55b8441f:latest\nviennaglobal.azurecr.io/azureml/azureml_30c8b4102ff1b91d5efbf92a55b8441f:latest\n2021-10-08T21:47:30Z The vmsize standard_ds11_v2 is not a GPU VM, skipping get GPU count by running nvidia-smi command.\n2021-10-08T21:47:30Z Check if container 9dc875a6-0c0b-48da-84d6-f6d103842640_DataSidecar already exist exited with 0, \n\nf551e8b4e8b32bda4104717a3e852db70609babd4ee3e573d1f6756afb0033bf\n2021-10-08T21:47:30Z Parameters for containerSetup task: useDetonationChamer set to false and sshRequired set to false \n2021-10-08T21:47:30Z containerSetup task cmd: [/mnt/batch/tasks/startup/wd/hosttools -task=containerSetup -traceContext=00-39d40916ab5bc0855578662e5f87db6c-ada2c58a63479607-01 -sshRequired=false] \n2021/10/08 21:47:30 Got JobInfoJson from env\n2021/10/08 21:47:30 Starting App Insight Logger for task:  containerSetup\n2021/10/08 21:47:30 Version: 3.0.01734.0003 Branch: .SourceBranch Commit: 21dafbb\n2021/10/08 21:47:30 Entered ContainerSetupTask - Preparing infiniband\n2021/10/08 21:47:30 Starting infiniband setup\n2021/10/08 21:47:30 Python Version found is Python 3.7.9\n\n2021/10/08 21:47:30 Returning Python Version as 3.7\n2021-10-08T21:47:30Z VMSize: standard_ds11_v2, Host: runtime-gen1-ubuntu18, Container: ubuntu-16.04\n2021/10/08 21:47:30 VMSize: standard_ds11_v2, Host: runtime-gen1-ubuntu18, Container: ubuntu-16.04\n2021/10/08 21:47:30 VMSize: standard_ds11_v2, Host: runtime-gen1-ubuntu18, Container: ubuntu-16.04\n2021/10/08 21:47:30 /dev/infiniband/uverbs0 found (implying presence of InfiniBand)?: false\n2021-10-08T21:47:30Z Not setting up Infiniband in Container\n2021/10/08 21:47:30 Not setting up Infiniband in Container\n2021/10/08 21:47:30 Not setting up Infiniband in Container\n2021/10/08 21:47:30 Python Version found is Python 3.7.9\n\n2021/10/08 21:47:30 Returning Python Version as 3.7\n2021/10/08 21:47:30 sshd inside container not required for job, skipping setup.\n2021/10/08 21:47:31 All App Insights Logs was sent successfully or the close timeout of 10 was reached\n2021/10/08 21:47:31 App Insight Client has already been closed\n2021/10/08 21:47:31 Not exporting to RunHistory as the exporter is either stopped or there is no data.\nStopped: false\nOriginalData: 1\nFilteredData: 0.\n2021-10-08T21:47:31Z Starting docker container succeeded.\n2021-10-08T21:47:31Z The vmsize standard_ds11_v2 is not a GPU VM, skipping get GPU count by running nvidia-smi command.\n2021-10-08T21:47:41Z The vmsize standard_ds11_v2 is not a GPU VM, skipping get GPU count by running nvidia-smi command.\n2021-10-08T21:47:41Z The vmsize standard_ds11_v2 is not a GPU VM, skipping get GPU count by running nvidia-smi command.\n2021-10-08T21:47:42Z Executing 'Copy ACR Details file' on 10.0.0.4\n2021-10-08T21:47:42Z Copy ACR Details file succeeded on 10.0.0.4. Output: \n>>>   \n>>>   \nLogin Succeeded\nUsing default tag: latest\nlatest: Pulling from azureml/azureml_21ec214220b650a356d20fde58334d25\nDigest: sha256:f24929cba9fb0a220c7461976ad7fb3e2b96d614a29379b98de4559620c9665e\nStatus: Image is up to date for 43960628131b4266b2d2072e89e00bd8.azurecr.io/azureml/azureml_21ec214220b650a356d20fde58334d25:latest\n43960628131b4266b2d2072e89e00bd8.azurecr.io/azureml/azureml_21ec214220b650a356d20fde58334d25:latest\n2021-10-08T21:47:42Z The vmsize standard_ds11_v2 is not a GPU VM, skipping get GPU count by running nvidia-smi command.\n2021-10-08T21:47:42Z Check if container 9dc875a6-0c0b-48da-84d6-f6d103842640 already exist exited with 0, f551e8b4e8b3\n\n\n2021-10-08T21:47:42Z The container 9dc875a6-0c0b-48da-84d6-f6d103842640 already exists, stop and remove it before starting it.\n2021-10-08T21:47:42Z Stopping container 9dc875a6-0c0b-48da-84d6-f6d103842640 exited with 1, Error response from daemon: No such container: 9dc875a6-0c0b-48da-84d6-f6d103842640\n\n\n2021-10-08T21:47:42Z Removing container 9dc875a6-0c0b-48da-84d6-f6d103842640 exited with 1, Error: No such container: 9dc875a6-0c0b-48da-84d6-f6d103842640\n\n\nc50bcf1ec1a249e1c3cba4cf267136daff92f0a34c78ab120f020a4f9781b1c7\n2021-10-08T21:47:42Z Parameters for containerSetup task: useDetonationChamer set to false and sshRequired set to false \n2021-10-08T21:47:42Z containerSetup task cmd: [/mnt/batch/tasks/startup/wd/hosttools -task=containerSetup -traceContext=00-39d40916ab5bc0855578662e5f87db6c-8383d19098721045-01 -sshRequired=false] \n2021/10/08 21:47:42 Got JobInfoJson from env\n2021/10/08 21:47:42 Starting App Insight Logger for task:  containerSetup\n2021/10/08 21:47:42 Version: 3.0.01734.0003 Branch: .SourceBranch Commit: 21dafbb\n2021/10/08 21:47:42 Entered ContainerSetupTask - Preparing infiniband\n2021/10/08 21:47:42 Starting infiniband setup\n2021/10/08 21:47:42 Python Version found is Python 3.6.2 :: Anaconda, Inc.\n\n2021/10/08 21:47:42 Returning Python Version as 3.6\n2021/10/08 21:47:42 VMSize: standard_ds11_v2, Host: runtime-gen1-ubuntu18, Container: ubuntu-18.04\n2021/10/08 21:47:42 VMSize: standard_ds11_v2, Host: runtime-gen1-ubuntu18, Container: ubuntu-18.04\n2021-10-08T21:47:42Z VMSize: standard_ds11_v2, Host: runtime-gen1-ubuntu18, Container: ubuntu-18.04\n2021/10/08 21:47:42 /dev/infiniband/uverbs0 found (implying presence of InfiniBand)?: false\n2021/10/08 21:47:42 Not setting up Infiniband in Container\n2021/10/08 21:47:42 Not setting up Infiniband in Container\n2021-10-08T21:47:42Z Not setting up Infiniband in Container\n2021/10/08 21:47:42 Python Version found is Python 3.6.2 :: Anaconda, Inc.\n\n2021/10/08 21:47:42 Returning Python Version as 3.6\n2021/10/08 21:47:42 sshd inside container not required for job, skipping setup.\n2021/10/08 21:47:43 All App Insights Logs was sent successfully or the close timeout of 10 was reached\n2021/10/08 21:47:43 App Insight Client has already been closed\n2021/10/08 21:47:43 Not exporting to RunHistory as the exporter is either stopped or there is no data.\nStopped: false\nOriginalData: 1\nFilteredData: 0.\n2021-10-08T21:47:43Z Starting docker container succeeded.\n2021-10-08T21:47:43Z Job environment preparation succeeded on 10.0.0.4. Output: \n>>>   2021/10/08 21:47:28 Got JobInfoJson from env\n>>>   2021/10/08 21:47:28 Starting App Insight Logger for task:  prepareJobEnvironment\n>>>   2021/10/08 21:47:28 Version: 3.0.01734.0003 Branch: .SourceBranch Commit: 21dafbb\n>>>   2021/10/08 21:47:28 Got JobInfoJson from env\n>>>   2021/10/08 21:47:28 runtime.GOOS linux\n>>>   2021/10/08 21:47:28 Checking if '/tmp' exists\n>>>   2021/10/08 21:47:28 Reading dyanamic configs\n>>>   2021/10/08 21:47:28 Container sas url: https://baiscriptseastusprod.blob.core.windows.net/aihosttools?sv=2018-03-28&sr=c&si=aihosttoolspolicy&sig=gCpFfTbL8hPl%2BzV43hBdfOZC4SuKqZoJraIo10S4%2FYw%3D\n>>>   2021/10/08 21:47:28 Failed to read from file /mnt/batch/tasks/startup/wd/az_resource/azsecpack.variables, open /mnt/batch/tasks/startup/wd/az_resource/azsecpack.variables: no such file or directory\n>>>   2021/10/08 21:47:28 [in autoUpgradeFromJobNodeSetup] Is Azsecpack installer on host: true. Is Azsecpack installation enabled: false,\n>>>   2021/10/08 21:47:28 Starting Azsecpack installation on machine: fb68c8530fe6416c9b62423809c0aab7000000#669832bc-1c49-401d-84ca-5fe95035ead2#448781ce-ecdd-4bf3-91e9-5674666ebec1#ict-915-02-jmdl#ict-915-02-jmdl#ct-915-02-jmdl#tvmps_e1613ff6135641c2a128b0ffb7f6b5266031aeab8c73b5f1d1e07eed6cfba49d_d\n>>>   2021/10/08 21:47:28 Is Azsecpack enabled: false, GetDisableVsatlsscan: true\n>>>   2021/10/08 21:47:28 Turning off azsecpack, if it is already running\n>>>   2021/10/08 21:47:28 Start deleting Azsecpack installation cronjob...\n>>>   2021/10/08 21:47:28 Start checking if Azsecpack is running...\n>>>   2021/10/08 21:47:28 Azsecpack is not running. No need to stop Azsecpack processes.\n>>>   2021/10/08 21:47:28 Job: AZ_BATCHAI_JOB_NAME does not turn on the DetonationChamber\n>>>   2021/10/08 21:47:28 The vmsize standard_ds11_v2 is not a GPU VM, skipping get GPU count by running nvidia-smi command.\n>>>   2021/10/08 21:47:28 The vmsize standard_ds11_v2 is not a GPU VM, skipping get GPU count by running nvidia-smi command.\n>>>   2021/10/08 21:47:28 Get GPU count failed with err: The vmsize standard_ds11_v2 is not a GPU VM, skipping get GPU count by running nvidia-smi command., \n>>>   2021/10/08 21:47:28 AMLComputeXDSEndpoint:  https://eastus.cert.api.azureml.ms/xdsbatchai\n>>>   2021/10/08 21:47:28 AMLComputeXDSApiVersion:  2018-02-01\n>>>   2021/10/08 21:47:28 Creating directory /mnt/batch/tasks/shared/LS_root/jobs/ict-915-02-jmdl/azureml/9dc875a6-0c0b-48da-84d6-f6d103842640/config\n>>>   2021/10/08 21:47:28 This is not a aml-workstation (compute instance), current offer type: amlcompute. Starting identity responder as part of prepareJobEnvironment.\n>>>   2021/10/08 21:47:28 Starting identity responder.\n>>>   2021/10/08 21:47:28 Starting identity responder.\n>>>   2021/10/08 21:47:28 Logfile used for identity responder: /mnt/batch/tasks/workitems/f04b5c8c-5c4c-4274-a2fe-c93ca90b5e20/job-1/9dc875a6-0c0b-48da-8_a2cd738a-0b92-4635-9895-740b6ddd8f8d/IdentityResponderLog-tvmps_e1613ff6135641c2a128b0ffb7f6b5266031aeab8c73b5f1d1e07eed6cfba49d_d.txt\n>>>   2021/10/08 21:47:28 Logfile used for identity responder: /mnt/batch/tasks/workitems/f04b5c8c-5c4c-4274-a2fe-c93ca90b5e20/job-1/9dc875a6-0c0b-48da-8_a2cd738a-0b92-4635-9895-740b6ddd8f8d/IdentityResponderLog-tvmps_e1613ff6135641c2a128b0ffb7f6b5266031aeab8c73b5f1d1e07eed6cfba49d_d.txt\n>>>   2021/10/08 21:47:28 Started Identity Responder for job.\n>>>   2021/10/08 21:47:28 Started Identity Responder for job.\n>>>   2021/10/08 21:47:28 Creating directory /mnt/batch/tasks/shared/LS_root/jobs/ict-915-02-jmdl/azureml/9dc875a6-0c0b-48da-84d6-f6d103842640/wd\n>>>   2021/10/08 21:47:28 Creating directory /mnt/batch/tasks/shared/LS_root/jobs/ict-915-02-jmdl/azureml/9dc875a6-0c0b-48da-84d6-f6d103842640/shared\n>>>   2021/10/08 21:47:28 WorkingDirPath is specified. Setting env AZ_BATCHAI_JOB_WORK_DIR=$AZ_BATCHAI_JOB_TEMP/azureml/9dc875a6-0c0b-48da-84d6-f6d103842640\n>>>   2021/10/08 21:47:28 From the policy service, the filtering patterns is: , data store is \n>>>   2021/10/08 21:47:28 Mounting job level file systems\n>>>   2021/10/08 21:47:28 Creating directory /mnt/batch/tasks/shared/LS_root/jobs/ict-915-02-jmdl/azureml/9dc875a6-0c0b-48da-84d6-f6d103842640/mounts\n>>>   2021/10/08 21:47:28 Attempting to read datastore credentials file: /mnt/batch/tasks/shared/LS_root/jobs/ict-915-02-jmdl/azureml/9dc875a6-0c0b-48da-84d6-f6d103842640/config/.amlcompute.datastorecredentials\n>>>   2021/10/08 21:47:28 Datastore credentials file not found, skipping.\n>>>   2021/10/08 21:47:28 Attempting to read runtime sas tokens file: /mnt/batch/tasks/shared/LS_root/jobs/ict-915-02-jmdl/azureml/9dc875a6-0c0b-48da-84d6-f6d103842640/config/.master.runtimesastokens\n>>>   2021/10/08 21:47:28 Runtime sas tokens file not found, skipping.\n>>>   2021/10/08 21:47:28 NFS mount is not enabled\n>>>   2021/10/08 21:47:28 No Azure File Shares configured\n>>>   2021/10/08 21:47:28 Mounting blob file systems\n>>>   2021/10/08 21:47:28 Blobfuse runtime version 1.3.6\n>>>   2021/10/08 21:47:28 Mounting azureml-blobstore-43960628-131b-4266-b2d2-072e89e00bd8 container from ict91502jmdl5971809827 account at /mnt/batch/tasks/shared/LS_root/jobs/ict-915-02-jmdl/azureml/9dc875a6-0c0b-48da-84d6-f6d103842640/mounts/workspaceblobstore\n>>>   2021/10/08 21:47:28 Using Compute Identity to authenticate Blobfuse: false.\n>>>   2021/10/08 21:47:28 Using Compute Identity to authenticate Blobfuse: false.\n>>>   2021/10/08 21:47:28 Blobfuse cache size set to 20284 MB.\n>>>   2021/10/08 21:47:28 Running following command: /bin/bash -c sudo blobfuse /mnt/batch/tasks/shared/LS_root/jobs/ict-915-02-jmdl/azureml/9dc875a6-0c0b-48da-84d6-f6d103842640/mounts/workspaceblobstore --tmp-path=/mnt/batch/tasks/shared/LS_root/jobs/ict-915-02-jmdl/azureml/9dc875a6-0c0b-48da-84d6-f6d103842640/caches/workspaceblobstore -o ro --file-cache-timeout-in-seconds=1000000 --cache-size-mb=20284 -o nonempty -o allow_other --config-file=/mnt/batch/tasks/shared/LS_root/jobs/ict-915-02-jmdl/azureml/9dc875a6-0c0b-48da-84d6-f6d103842640/configs/workspaceblobstore.cfg --log-level=LOG_WARNING\n>>>   2021/10/08 21:47:28 Successfully mounted a/an Blobfuse File System at /mnt/batch/tasks/shared/LS_root/jobs/ict-915-02-jmdl/azureml/9dc875a6-0c0b-48da-84d6-f6d103842640/mounts/workspaceblobstore\n>>>   2021/10/08 21:47:28 Waiting for blobfs to be mounted at /mnt/batch/tasks/shared/LS_root/jobs/ict-915-02-jmdl/azureml/9dc875a6-0c0b-48da-84d6-f6d103842640/mounts/workspaceblobstore\n>>>   2021/10/08 21:47:28 Successfully mounted azureml-blobstore-43960628-131b-4266-b2d2-072e89e00bd8 container from ict91502jmdl5971809827 account at /mnt/batch/tasks/shared/LS_root/jobs/ict-915-02-jmdl/azureml/9dc875a6-0c0b-48da-84d6-f6d103842640/mounts/workspaceblobstore\n>>>   2021/10/08 21:47:29 Failed to created run_id directory: /mnt/batch/tasks/shared/LS_root/jobs/ict-915-02-jmdl/azureml/9dc875a6-0c0b-48da-84d6-f6d103842640/mounts/workspaceblobstore/azureml/9dc875a6-0c0b-48da-84d6-f6d103842640, due to mkdir /mnt/batch/tasks/shared/LS_root/jobs/ict-915-02-jmdl/azureml/9dc875a6-0c0b-48da-84d6-f6d103842640/mounts/workspaceblobstore/azureml/9dc875a6-0c0b-48da-84d6-f6d103842640: read-only file system\n>>>   2021/10/08 21:47:29 No unmanaged file systems configured\n>>>   2021/10/08 21:47:29 The vmsize standard_ds11_v2 is not a GPU VM, skipping get GPU count by running nvidia-smi command.\n>>>   2021/10/08 21:47:29 The vmsize standard_ds11_v2 is not a GPU VM, skipping get GPU count by running nvidia-smi command.\n>>>   2021/10/08 21:47:29 WorkingDirPath is specified. Setting env AZ_BATCHAI_JOB_WORK_DIR=$AZ_BATCHAI_JOB_TEMP/azureml/9dc875a6-0c0b-48da-84d6-f6d103842640\n>>>   2021/10/08 21:47:29 From the policy service, the filtering patterns is: , data store is \n>>>   2021/10/08 21:47:29 Creating working directory: /mnt/batch/tasks/shared/LS_root/jobs/ict-915-02-jmdl/azureml/9dc875a6-0c0b-48da-84d6-f6d103842640/wd/azureml/9dc875a6-0c0b-48da-84d6-f6d103842640\n>>>   2021/10/08 21:47:29 Creating directory /mnt/batch/tasks/shared/LS_root/jobs/ict-915-02-jmdl/azureml/9dc875a6-0c0b-48da-84d6-f6d103842640/wd/azureml/9dc875a6-0c0b-48da-84d6-f6d103842640\n>>>   2021/10/08 21:47:29 Changing permissions for all existing files under directory: /mnt/batch/tasks/shared/LS_root/jobs/ict-915-02-jmdl/azureml/9dc875a6-0c0b-48da-84d6-f6d103842640/wd/azureml/9dc875a6-0c0b-48da-84d6-f6d103842640\n>>>   2021/10/08 21:47:29 Change mode to 777 for dir /mnt/batch/tasks/shared/LS_root/jobs/ict-915-02-jmdl/azureml/9dc875a6-0c0b-48da-84d6-f6d103842640/wd/azureml/9dc875a6-0c0b-48da-84d6-f6d103842640\n>>>   2021/10/08 21:47:29 Change mode to 777 for dir /mnt/batch/tasks/shared/LS_root/jobs/ict-915-02-jmdl/azureml/9dc875a6-0c0b-48da-84d6-f6d103842640/wd/azureml/9dc875a6-0c0b-48da-84d6-f6d103842640/azureml_compute_logs\n>>>   2021/10/08 21:47:29 Change mode to 777 for dir /mnt/batch/tasks/shared/LS_root/jobs/ict-915-02-jmdl/azureml/9dc875a6-0c0b-48da-84d6-f6d103842640/wd/azureml/9dc875a6-0c0b-48da-84d6-f6d103842640/azureml_compute_logs/tvmps_e1613ff6135641c2a128b0ffb7f6b5266031aeab8c73b5f1d1e07eed6cfba49d_d\n>>>   2021/10/08 21:47:29 Change mode to 666 for file /mnt/batch/tasks/shared/LS_root/jobs/ict-915-02-jmdl/azureml/9dc875a6-0c0b-48da-84d6-f6d103842640/wd/azureml/9dc875a6-0c0b-48da-84d6-f6d103842640/azureml_compute_logs/tvmps_e1613ff6135641c2a128b0ffb7f6b5266031aeab8c73b5f1d1e07eed6cfba49d_d/55_azureml-execution-tvmps_e1613ff6135641c2a128b0ffb7f6b5266031aeab8c73b5f1d1e07eed6cfba49d_d.txt\n>>>   2021/10/08 21:47:29 Set default ACL for files under directory by running: /usr/bin/setfacl -m default:g::rwx -m default:o::rwx /mnt/batch/tasks/shared/LS_root/jobs/ict-915-02-jmdl/azureml/9dc875a6-0c0b-48da-84d6-f6d103842640/wd/azureml/9dc875a6-0c0b-48da-84d6-f6d103842640\n>>>   2021/10/08 21:47:29 Creating directory /mnt/batch/tasks/shared/LS_root/jobs/ict-915-02-jmdl/azureml/9dc875a6-0c0b-48da-84d6-f6d103842640/wd/azureml/9dc875a6-0c0b-48da-84d6-f6d103842640/azureml_compute_logs\n>>>   2021/10/08 21:47:29 Changing permissions for all existing files under directory: /mnt/batch/tasks/shared/LS_root/jobs/ict-915-02-jmdl/azureml/9dc875a6-0c0b-48da-84d6-f6d103842640/wd/azureml/9dc875a6-0c0b-48da-84d6-f6d103842640/azureml_compute_logs\n>>>   2021/10/08 21:47:29 Change mode to 777 for dir /mnt/batch/tasks/shared/LS_root/jobs/ict-915-02-jmdl/azureml/9dc875a6-0c0b-48da-84d6-f6d103842640/wd/azureml/9dc875a6-0c0b-48da-84d6-f6d103842640/azureml_compute_logs\n>>>   2021/10/08 21:47:29 Change mode to 777 for dir /mnt/batch/tasks/shared/LS_root/jobs/ict-915-02-jmdl/azureml/9dc875a6-0c0b-48da-84d6-f6d103842640/wd/azureml/9dc875a6-0c0b-48da-84d6-f6d103842640/azureml_compute_logs/tvmps_e1613ff6135641c2a128b0ffb7f6b5266031aeab8c73b5f1d1e07eed6cfba49d_d\n>>>   2021/10/08 21:47:29 Change mode to 666 for file /mnt/batch/tasks/shared/LS_root/jobs/ict-915-02-jmdl/azureml/9dc875a6-0c0b-48da-84d6-f6d103842640/wd/azureml/9dc875a6-0c0b-48da-84d6-f6d103842640/azureml_compute_logs/tvmps_e1613ff6135641c2a128b0ffb7f6b5266031aeab8c73b5f1d1e07eed6cfba49d_d/55_azureml-execution-tvmps_e1613ff6135641c2a128b0ffb7f6b5266031aeab8c73b5f1d1e07eed6cfba49d_d.txt\n>>>   2021/10/08 21:47:29 Set default ACL for files under directory by running: /usr/bin/setfacl -m default:g::rwx -m default:o::rwx /mnt/batch/tasks/shared/LS_root/jobs/ict-915-02-jmdl/azureml/9dc875a6-0c0b-48da-84d6-f6d103842640/wd/azureml/9dc875a6-0c0b-48da-84d6-f6d103842640/azureml_compute_logs\n>>>   2021/10/08 21:47:29 Creating directory /mnt/batch/tasks/shared/LS_root/jobs/ict-915-02-jmdl/azureml/9dc875a6-0c0b-48da-84d6-f6d103842640/wd/azureml/9dc875a6-0c0b-48da-84d6-f6d103842640/logs\n>>>   2021/10/08 21:47:29 Creating directory /mnt/batch/tasks/shared/LS_root/jobs/ict-915-02-jmdl/azureml/9dc875a6-0c0b-48da-84d6-f6d103842640/wd/azureml/9dc875a6-0c0b-48da-84d6-f6d103842640/outputs\n>>>   2021/10/08 21:47:29 Starting output-watcher...\n>>>   2021/10/08 21:47:29 Single file input dataset is enabled.\n>>>   2021/10/08 21:47:29 SidecarEnabled:: isDetonationChamber: false, useDockerContainer: true\n>>>   2021/10/08 21:47:29 SidecarEnabled:: AmlDatasetContextManagerConfig exists: true\n>>>   2021/10/08 21:47:29 SidecarEnabled:: enabling sidecar due to dataset being present and sidecar is enabled\n>>>   2021/10/08 21:47:29 Begin Sidecar setup\n>>>   2021/10/08 21:47:29 SingleDataDirectory enabled, Passing to Sidecar.\n>>>   2021/10/08 21:47:29 Pulling Sidecar docker image: azureml/azureml_30c8b4102ff1b91d5efbf92a55b8441f\n>>>   2021/10/08 21:47:29 Start pull docker image: azureml\n>>>   2021/10/08 21:47:29 Getting credentials for image azureml/azureml_30c8b4102ff1b91d5efbf92a55b8441f with url \n>>>   2021/10/08 21:47:29 Container registry is not ACR.\n>>>   2021/10/08 21:47:29 Skip getting ACR Credentials from Identity and will be getting it from EMS\n>>>   2021/10/08 21:47:29 Getting ACR Credentials from EMS for environment AzureML-Sidecar:22\n>>>   2021/10/08 21:47:29 Requesting XDS for registry details.\n>>>   2021/10/08 21:47:29 Attempt 1 of http call to https://eastus.cert.api.azureml.ms/xdsbatchai/hosttoolapi/subscriptions/448781ce-ecdd-4bf3-91e9-5674666ebec1/resourceGroups/ict-915-02-jmdl/workspaces/ict-915-02-jmdl/clusters/ct-915-02-jmdl/nodes/tvmps_e1613ff6135641c2a128b0ffb7f6b5266031aeab8c73b5f1d1e07eed6cfba49d_d?api-version=2018-02-01\n>>>   2021/10/08 21:47:29 Got container registry details from credentials service for registry address: viennaglobal.azurecr.io.\n>>>   2021/10/08 21:47:29 Writing ACR Details to file...\n>>>   2021/10/08 21:47:29 Copying ACR Details file to worker nodes...\n>>>   2021/10/08 21:47:29 Executing 'Copy ACR Details file' on 10.0.0.4\n>>>   2021/10/08 21:47:29 Begin executing 'Copy ACR Details file' task on Node\n>>>   2021/10/08 21:47:29 'Copy ACR Details file' task Node result: succeeded\n>>>   2021/10/08 21:47:29 Copy ACR Details file succeeded on 10.0.0.4. Output: \n>>>   >>>   \n>>>   >>>   \n>>>   2021/10/08 21:47:29 Successfully retrieved ACR Credentials from EMS.\n>>>   2021/10/08 21:47:29 EMS returned viennaglobal.azurecr.io for environment AzureML-Sidecar\n>>>   2021/10/08 21:47:29 Updating image url from blank to viennaglobal.azurecr.io\n>>>   2021/10/08 21:47:29 Save docker credentials for image viennaglobal.azurecr.io/azureml/azureml_30c8b4102ff1b91d5efbf92a55b8441f in /mnt/batch/tasks/shared/LS_root/jobs/ict-915-02-jmdl/azureml/9dc875a6-0c0b-48da-84d6-f6d103842640/wd/docker_login_E64E71885A69BD99\n>>>   2021/10/08 21:47:29 Start login to the docker registry\n>>>   2021/10/08 21:47:29 Successfully logged into the docker registry.\n>>>   2021/10/08 21:47:29 Start run pull docker image command\n>>>   2021/10/08 21:47:30 Pull docker image succeeded.\n>>>   2021/10/08 21:47:30 Removed docker config dir /mnt/batch/tasks/shared/LS_root/jobs/ict-915-02-jmdl/azureml/9dc875a6-0c0b-48da-84d6-f6d103842640/wd/docker_login_E64E71885A69BD99\n>>>   2021/10/08 21:47:30 Pull docker image time: 1.039598539s\n>>>   \n>>>   2021/10/08 21:47:30 Docker Version that this nodes use are: 19.03.14+azure\n>>>   \n>>>   2021/10/08 21:47:30 The vmsize standard_ds11_v2 is not a GPU VM, skipping get GPU count by running nvidia-smi command.\n>>>   2021/10/08 21:47:30 The vmsize standard_ds11_v2 is not a GPU VM, skipping get GPU count by running nvidia-smi command.\n>>>   2021/10/08 21:47:30 Setting the memory limit for docker container to be 13674 MB\n>>>   2021/10/08 21:47:30 The env variable file size is 41450 bytes\n>>>   2021/10/08 21:47:30 Creating parent cgroup '9dc875a6-0c0b-48da-84d6-f6d103842640' for Containers used in Job\n>>>   2021/10/08 21:47:30 Add parent cgroup '9dc875a6-0c0b-48da-84d6-f6d103842640' to container '9dc875a6-0c0b-48da-84d6-f6d103842640_DataSidecar'\n>>>   2021/10/08 21:47:30 /dev/infiniband/uverbs0 found (implying presence of InfiniBand)?: false\n>>>   2021/10/08 21:47:30 Original Arguments: run,--ulimit,memlock=9223372036854775807,--ulimit,nofile=262144:262144,--cap-add,sys_ptrace,--name,9dc875a6-0c0b-48da-84d6-f6d103842640_DataSidecar,-v,/mnt/batch/tasks/shared/LS_root/mounts:/mnt/batch/tasks/shared/LS_root/mounts:rshared,-v,/mnt/batch/tasks/shared/LS_root/configs:/mnt/batch/tasks/shared/LS_root/configs,-v,/mnt/batch/tasks/shared/LS_root/shared:/mnt/batch/tasks/shared/LS_root/shared,-v,/mnt/batch/tasks/workitems/f04b5c8c-5c4c-4274-a2fe-c93ca90b5e20/job-1/9dc875a6-0c0b-48da-8_a2cd738a-0b92-4635-9895-740b6ddd8f8d/certs:/mnt/batch/tasks/workitems/f04b5c8c-5c4c-4274-a2fe-c93ca90b5e20/job-1/9dc875a6-0c0b-48da-8_a2cd738a-0b92-4635-9895-740b6ddd8f8d/certs,-v,/mnt/batch/tasks/startup:/mnt/batch/tasks/startup,-m,13674m,-v,/mnt/batch/tasks/shared/LS_root/jobs/ict-915-02-jmdl/azureml/9dc875a6-0c0b-48da-84d6-f6d103842640/wd/azureml/9dc875a6-0c0b-48da-84d6-f6d103842640/azureml_compute_logs:/mnt/batch/tasks/shared/LS_root/jobs/ict-915-02-jmdl/azureml/9dc875a6-0c0b-48da-84d6-f6d103842640/wd/azureml/9dc875a6-0c0b-48da-84d6-f6d103842640/azureml_compute_logs,-v,/mnt/batch/tasks/workitems/f04b5c8c-5c4c-4274-a2fe-c93ca90b5e20/job-1/9dc875a6-0c0b-48da-8_a2cd738a-0b92-4635-9895-740b6ddd8f8d/wd:/mnt/batch/tasks/workitems/f04b5c8c-5c4c-4274-a2fe-c93ca90b5e20/job-1/9dc875a6-0c0b-48da-8_a2cd738a-0b92-4635-9895-740b6ddd8f8d/wd,-v,/mnt/batch/tasks/shared/LS_root/jobs/ict-915-02-jmdl/azureml/9dc875a6-0c0b-48da-84d6-f6d103842640:/mnt/batch/tasks/shared/LS_root/jobs/ict-915-02-jmdl/azureml/9dc875a6-0c0b-48da-84d6-f6d103842640,-v,/mnt/batch/tasks/shared/LS_root/shared/tracing/9dc875a6-0c0b-48da-84d6-f6d103842640/logs/azureml/tracing:/mnt/batch/tasks/shared/LS_root/shared/tracing/9dc875a6-0c0b-48da-84d6-f6d103842640/logs/azureml/tracing,-w,/mnt/batch/tasks/shared/LS_root/jobs/ict-915-02-jmdl/azureml/9dc875a6-0c0b-48da-84d6-f6d103842640/wd,--expose,23,--env-file,/mnt/batch/tasks/shared/LS_root/jobs/ict-915-02-jmdl/azureml/9dc875a6-0c0b-48da-84d6-f6d103842640/config/.batchai.envlist,--cgroup-parent=/9dc875a6-0c0b-48da-84d6-f6d103842640/,--shm-size,2g,-v,/:/mnt/hostfs:rshared,--env,SIDECAR_HOSTFS=/mnt/hostfs,--env,SIDECAR_WORKING_DIR=/mnt/hostfs/mnt/batch/tasks/shared/LS_root/jobs/ict-915-02-jmdl/azureml/9dc875a6-0c0b-48da-84d6-f6d103842640/wd/azureml/9dc875a6-0c0b-48da-84d6-f6d103842640,--env,AZ_BATCHAI_ENVLIST_PATH=/mnt/batch/tasks/shared/LS_root/jobs/ict-915-02-jmdl/azureml/9dc875a6-0c0b-48da-84d6-f6d103842640/config/.batchai.envlist,--env,AZUREML_SIDECAR_SINGLE_DATA_DIRECTORY=true,--env,RSLEX_DIRECT_VOLUME_MOUNT=true,--env,DATASET_RSLEX_UPLOAD=true\n>>>   2021/10/08 21:47:30 the binding /mnt/batch/tasks/shared/LS_root/shared/tracing/9dc875a6-0c0b-48da-84d6-f6d103842640/logs/azureml/tracing:/mnt/batch/tasks/shared/LS_root/shared/tracing/9dc875a6-0c0b-48da-84d6-f6d103842640/logs/azureml/tracing is discarded as we already have /mnt/batch/tasks/shared/LS_root/shared:/mnt/batch/tasks/shared/LS_root/shared \n>>>   2021/10/08 21:47:30 the binding /mnt/batch/tasks/shared/LS_root/jobs/ict-915-02-jmdl/azureml/9dc875a6-0c0b-48da-84d6-f6d103842640/wd/azureml/9dc875a6-0c0b-48da-84d6-f6d103842640/azureml_compute_logs:/mnt/batch/tasks/shared/LS_root/jobs/ict-915-02-jmdl/azureml/9dc875a6-0c0b-48da-84d6-f6d103842640/wd/azureml/9dc875a6-0c0b-48da-84d6-f6d103842640/azureml_compute_logs is discarded as we already have /mnt/batch/tasks/shared/LS_root/jobs/ict-915-02-jmdl/azureml/9dc875a6-0c0b-48da-84d6-f6d103842640:/mnt/batch/tasks/shared/LS_root/jobs/ict-915-02-jmdl/azureml/9dc875a6-0c0b-48da-84d6-f6d103842640 \n>>>   2021/10/08 21:47:30 Updated Arguments: run,--ulimit,memlock=9223372036854775807,--ulimit,nofile=262144:262144,--cap-add,sys_ptrace,--name,9dc875a6-0c0b-48da-84d6-f6d103842640_DataSidecar,-m,13674m,-w,/mnt/batch/tasks/shared/LS_root/jobs/ict-915-02-jmdl/azureml/9dc875a6-0c0b-48da-84d6-f6d103842640/wd,--expose,23,--env-file,/mnt/batch/tasks/shared/LS_root/jobs/ict-915-02-jmdl/azureml/9dc875a6-0c0b-48da-84d6-f6d103842640/config/.batchai.envlist,--cgroup-parent=/9dc875a6-0c0b-48da-84d6-f6d103842640/,--shm-size,2g,--env,SIDECAR_HOSTFS=/mnt/hostfs,--env,SIDECAR_WORKING_DIR=/mnt/hostfs/mnt/batch/tasks/shared/LS_root/jobs/ict-915-02-jmdl/azureml/9dc875a6-0c0b-48da-84d6-f6d103842640/wd/azureml/9dc875a6-0c0b-48da-84d6-f6d103842640,--env,AZ_BATCHAI_ENVLIST_PATH=/mnt/batch/tasks/shared/LS_root/jobs/ict-915-02-jmdl/azureml/9dc875a6-0c0b-48da-84d6-f6d103842640/config/.batchai.envlist,--env,AZUREML_SIDECAR_SINGLE_DATA_DIRECTORY=true,--env,RSLEX_DIRECT_VOLUME_MOUNT=true,--env,DATASET_RSLEX_UPLOAD=true,-v,/:/mnt/hostfs:rshared,-v,/mnt/batch/tasks/startup:/mnt/batch/tasks/startup,-v,/mnt/batch/tasks/shared/LS_root/mounts:/mnt/batch/tasks/shared/LS_root/mounts:rshared,-v,/mnt/batch/tasks/shared/LS_root/shared:/mnt/batch/tasks/shared/LS_root/shared,-v,/mnt/batch/tasks/shared/LS_root/configs:/mnt/batch/tasks/shared/LS_root/configs,-v,/mnt/batch/tasks/shared/LS_root/jobs/ict-915-02-jmdl/azureml/9dc875a6-0c0b-48da-84d6-f6d103842640:/mnt/batch/tasks/shared/LS_root/jobs/ict-915-02-jmdl/azureml/9dc875a6-0c0b-48da-84d6-f6d103842640,-v,/mnt/batch/tasks/workitems/f04b5c8c-5c4c-4274-a2fe-c93ca90b5e20/job-1/9dc875a6-0c0b-48da-8_a2cd738a-0b92-4635-9895-740b6ddd8f8d/wd:/mnt/batch/tasks/workitems/f04b5c8c-5c4c-4274-a2fe-c93ca90b5e20/job-1/9dc875a6-0c0b-48da-8_a2cd738a-0b92-4635-9895-740b6ddd8f8d/wd,-v,/mnt/batch/tasks/workitems/f04b5c8c-5c4c-4274-a2fe-c93ca90b5e20/job-1/9dc875a6-0c0b-48da-8_a2cd738a-0b92-4635-9895-740b6ddd8f8d/certs:/mnt/batch/tasks/workitems/f04b5c8c-5c4c-4274-a2fe-c93ca90b5e20/job-1/9dc875a6-0c0b-48da-8_a2cd738a-0b92-4635-9895-740b6ddd8f8d/certs\n>>>   2021/10/08 21:47:30 Running Docker command: docker run --ulimit memlock=9223372036854775807 --ulimit nofile=262144:262144 --cap-add sys_ptrace --name 9dc875a6-0c0b-48da-84d6-f6d103842640_DataSidecar -m 13674m -w /mnt/batch/tasks/shared/LS_root/jobs/ict-915-02-jmdl/azureml/9dc875a6-0c0b-48da-84d6-f6d103842640/wd --expose 23 --env-file /mnt/batch/tasks/shared/LS_root/jobs/ict-915-02-jmdl/azureml/9dc875a6-0c0b-48da-84d6-f6d103842640/config/.batchai.envlist --cgroup-parent=/9dc875a6-0c0b-48da-84d6-f6d103842640/ --shm-size 2g --env SIDECAR_HOSTFS=/mnt/hostfs --env SIDECAR_WORKING_DIR=/mnt/hostfs/mnt/batch/tasks/shared/LS_root/jobs/ict-915-02-jmdl/azureml/9dc875a6-0c0b-48da-84d6-f6d103842640/wd/azureml/9dc875a6-0c0b-48da-84d6-f6d103842640 --env AZ_BATCHAI_ENVLIST_PATH=/mnt/batch/tasks/shared/LS_root/jobs/ict-915-02-jmdl/azureml/9dc875a6-0c0b-48da-84d6-f6d103842640/config/.batchai.envlist --env AZUREML_SIDECAR_SINGLE_DATA_DIRECTORY=true --env RSLEX_DIRECT_VOLUME_MOUNT=true --env DATASET_RSLEX_UPLOAD=true -v /:/mnt/hostfs:rshared -v /mnt/batch/tasks/startup:/mnt/batch/tasks/startup -v /mnt/batch/tasks/shared/LS_root/mounts:/mnt/batch/tasks/shared/LS_root/mounts:rshared -v /mnt/batch/tasks/shared/LS_root/shared:/mnt/batch/tasks/shared/LS_root/shared -v /mnt/batch/tasks/shared/LS_root/configs:/mnt/batch/tasks/shared/LS_root/configs -v /mnt/batch/tasks/shared/LS_root/jobs/ict-915-02-jmdl/azureml/9dc875a6-0c0b-48da-84d6-f6d103842640:/mnt/batch/tasks/shared/LS_root/jobs/ict-915-02-jmdl/azureml/9dc875a6-0c0b-48da-84d6-f6d103842640 -v /mnt/batch/tasks/workitems/f04b5c8c-5c4c-4274-a2fe-c93ca90b5e20/job-1/9dc875a6-0c0b-48da-8_a2cd738a-0b92-4635-9895-740b6ddd8f8d/wd:/mnt/batch/tasks/workitems/f04b5c8c-5c4c-4274-a2fe-c93ca90b5e20/job-1/9dc875a6-0c0b-48da-8_a2cd738a-0b92-4635-9895-740b6ddd8f8d/wd -v /mnt/batch/tasks/workitems/f04b5c8c-5c4c-4274-a2fe-c93ca90b5e20/job-1/9dc875a6-0c0b-48da-8_a2cd738a-0b92-4635-9895-740b6ddd8f8d/certs:/mnt/batch/tasks/workitems/f04b5c8c-5c4c-4274-a2fe-c93ca90b5e20/job-1/9dc875a6-0c0b-48da-8_a2cd738a-0b92-4635-9895-740b6ddd8f8d/certs -d -it --privileged --net=host viennaglobal.azurecr.io/azureml/azureml_30c8b4102ff1b91d5efbf92a55b8441f\n>>>   2021/10/08 21:47:30 Check if container 9dc875a6-0c0b-48da-84d6-f6d103842640_DataSidecar already exist exited with 0, \n>>>   \n>>>   2021/10/08 21:47:30 Check if container 9dc875a6-0c0b-48da-84d6-f6d103842640_DataSidecar already exist exited with 0, \n>>>   \n>>>   2021/10/08 21:47:30 Parameters for containerSetup task: useDetonationChamer set to false and sshRequired set to false \n>>>   2021/10/08 21:47:30 Parameters for containerSetup task: useDetonationChamer set to false and sshRequired set to false \n>>>   2021/10/08 21:47:30 containerSetup task cmd: [/mnt/batch/tasks/startup/wd/hosttools -task=containerSetup -traceContext=00-39d40916ab5bc0855578662e5f87db6c-ada2c58a63479607-01 -sshRequired=false] \n>>>   2021/10/08 21:47:30 containerSetup task cmd: [/mnt/batch/tasks/startup/wd/hosttools -task=containerSetup -traceContext=00-39d40916ab5bc0855578662e5f87db6c-ada2c58a63479607-01 -sshRequired=false] \n>>>   2021/10/08 21:47:31 Container ssh is not required for job type.\n>>>   2021/10/08 21:47:31 Starting docker container succeeded.\n>>>   2021/10/08 21:47:31 Starting docker container succeeded.\n>>>   2021/10/08 21:47:31 Docker Version that this nodes use are: 19.03.14+azure\n>>>   \n>>>   2021/10/08 21:47:31 The vmsize standard_ds11_v2 is not a GPU VM, skipping get GPU count by running nvidia-smi command.\n>>>   2021/10/08 21:47:31 The vmsize standard_ds11_v2 is not a GPU VM, skipping get GPU count by running nvidia-smi command.\n>>>   2021/10/08 21:47:31 Waiting for sidecar container 9dc875a6-0c0b-48da-84d6-f6d103842640_DataSidecar to start running.\n>>>   2021/10/08 21:47:31 Running command /usr/bin/docker inspect -f {{.State.Running}} 9dc875a6-0c0b-48da-84d6-f6d103842640_DataSidecar\n>>>   2021/10/08 21:47:31 Waiting for sidecar container to be ready.\n>>>   2021/10/08 21:47:31 Running command /usr/bin/docker exec 9dc875a6-0c0b-48da-84d6-f6d103842640_DataSidecar sh -c python -c 'from azureml.sidecar.ipc import IPC_FILE;import os;print(\"IsSidecarReady:{}\".format(os.path.exists(IPC_FILE)))'\n>>>   2021/10/08 21:47:32 Sidecar container is running and TaskServer is ready.\n>>>   2021/10/08 21:47:32 Run job preparation command in Sidecar container\n>>>   2021/10/08 21:47:32 runSpecialJobTask: checking control script content under dir: /mnt/batch/tasks/shared/LS_root/jobs/ict-915-02-jmdl/azureml/9dc875a6-0c0b-48da-84d6-f6d103842640/mounts/workspaceblobstore/azureml/9dc875a6-0c0b-48da-84d6-f6d103842640-setup\n>>>   2021/10/08 21:47:33 Attempt 1 of http call to https://eastus.api.azureml.ms/history/v1.0/private/subscriptions/448781ce-ecdd-4bf3-91e9-5674666ebec1/resourceGroups/ict-915-02-jmdl/providers/Microsoft.MachineLearningServices/workspaces/ict-915-02-jmdl/runs/9dc875a6-0c0b-48da-84d6-f6d103842640/spans\n>>>   2021/10/08 21:47:34 runSpecialJobTask: control script dir content: [_tracer.py: size=2022 md5=4c1dd974ef27d1cbec1434a93802ac73; _tracing.py: size=26407 md5=64b473943a5d2905628a9b2097f18081; _vendor_jwt_decode.py: size=2277 md5=d4b49e48ed904f03a4d6ad2f64f17368; azureml_globals.py: size=12242 md5=3700b728b132e633c956f368d13818e4; context_managers.py: size=48073 md5=1d499aa329dc1debda235d60098e98dd; job_prep.py: size=11214 md5=13bb64f32d440c1fbaff3644045668fc; log_history_status.py: size=4428 md5=778bbe2bb6cb72340d4344366f752a63; request_utilities.py: size=1185 md5=e053daf561ffebe1c54811d9dc11beaa; run_token_provider.py: size=4228 md5=b167c8697df9c999e3676723caa93cb3; utility_context_managers.py: size=5015 md5=824d969dee21cf92733986c744d17142]\n>>>   2021/10/08 21:47:34 runSpecialJobTask: os.GetEnv constants.StdouterrDir: /mnt/batch/tasks/shared/LS_root/jobs/ict-915-02-jmdl/azureml/9dc875a6-0c0b-48da-84d6-f6d103842640/wd/azureml/9dc875a6-0c0b-48da-84d6-f6d103842640/azureml_compute_logs\n>>>   2021/10/08 21:47:34 runSpecialJobTask: Raw cmd for preparation is passed is: python /mnt/batch/tasks/shared/LS_root/jobs/ict-915-02-jmdl/azureml/9dc875a6-0c0b-48da-84d6-f6d103842640/mounts/workspaceblobstore/azureml/9dc875a6-0c0b-48da-84d6-f6d103842640-setup/job_prep.py --snapshots '[{\"Id\":\"12c67a3e-2174-4906-97de-c1712432976e\",\"PathStack\":[\".\"],\"SnapshotEntityId\":null}]'\n>>>   2021/10/08 21:47:34 runSpecialJobTask: stdout path for preparation is passed is: /mnt/batch/tasks/shared/LS_root/jobs/ict-915-02-jmdl/azureml/9dc875a6-0c0b-48da-84d6-f6d103842640/wd/azureml/9dc875a6-0c0b-48da-84d6-f6d103842640/azureml_compute_logs/65_job_prep-tvmps_e1613ff6135641c2a128b0ffb7f6b5266031aeab8c73b5f1d1e07eed6cfba49d_d.txt\n>>>   2021/10/08 21:47:34 runSpecialJobTask: stderr path for preparation is passed is: /mnt/batch/tasks/shared/LS_root/jobs/ict-915-02-jmdl/azureml/9dc875a6-0c0b-48da-84d6-f6d103842640/wd/azureml/9dc875a6-0c0b-48da-84d6-f6d103842640/azureml_compute_logs/65_job_prep-tvmps_e1613ff6135641c2a128b0ffb7f6b5266031aeab8c73b5f1d1e07eed6cfba49d_d.txt\n>>>   2021/10/08 21:47:34 native cmd: export AZUREML_JOB_TASK_ERROR_PATH='/mnt/batch/tasks/workitems/f04b5c8c-5c4c-4274-a2fe-c93ca90b5e20/job-1/9dc875a6-0c0b-48da-8_a2cd738a-0b92-4635-9895-740b6ddd8f8d/wd/runSpecialJobTask_error.json';cd /mnt/batch/tasks/shared/LS_root/jobs/ict-915-02-jmdl/azureml/9dc875a6-0c0b-48da-84d6-f6d103842640/wd/azureml/9dc875a6-0c0b-48da-84d6-f6d103842640;python /mnt/batch/tasks/shared/LS_root/jobs/ict-915-02-jmdl/azureml/9dc875a6-0c0b-48da-84d6-f6d103842640/mounts/workspaceblobstore/azureml/9dc875a6-0c0b-48da-84d6-f6d103842640-setup/job_prep.py --snapshots '[{\"Id\":\"12c67a3e-2174-4906-97de-c1712432976e\",\"PathStack\":[\".\"],\"SnapshotEntityId\":null}]'\n>>>   2021/10/08 21:47:34 runSpecialJobTask: commons.GetOsPlatform(): ubuntu\n>>>   2021/10/08 21:47:34 runSpecialJobTask: Running cmd: /usr/bin/docker exec -e AZUREML_SDK_TRACEPARENT=00-39d40916ab5bc0855578662e5f87db6c-fc2e142ec32dc99d-01 -t 9dc875a6-0c0b-48da-84d6-f6d103842640_DataSidecar bash -c if [ -f ~/.bashrc ]; then PS1_back=$PS1; PS1='$'; . ~/.bashrc; PS1=$PS1_back; fi;PATH=$PATH:$AZ_BATCH_NODE_STARTUP_DIR/wd/;export AZUREML_JOB_TASK_ERROR_PATH='/mnt/batch/tasks/workitems/f04b5c8c-5c4c-4274-a2fe-c93ca90b5e20/job-1/9dc875a6-0c0b-48da-8_a2cd738a-0b92-4635-9895-740b6ddd8f8d/wd/runSpecialJobTask_error.json';cd /mnt/batch/tasks/shared/LS_root/jobs/ict-915-02-jmdl/azureml/9dc875a6-0c0b-48da-84d6-f6d103842640/wd/azureml/9dc875a6-0c0b-48da-84d6-f6d103842640;python /mnt/batch/tasks/shared/LS_root/jobs/ict-915-02-jmdl/azureml/9dc875a6-0c0b-48da-84d6-f6d103842640/mounts/workspaceblobstore/azureml/9dc875a6-0c0b-48da-84d6-f6d103842640-setup/job_prep.py --snapshots '[{\"Id\":\"12c67a3e-2174-4906-97de-c1712432976e\",\"PathStack\":[\".\"],\"SnapshotEntityId\":null}]'\n>>>   2021/10/08 21:47:41 containerName:9dc875a6-0c0b-48da-84d6-f6d103842640_DataSidecar\n>>>   2021/10/08 21:47:41 sidecar containerName:9dc875a6-0c0b-48da-84d6-f6d103842640_DataSidecar\n>>>   2021/10/08 21:47:41 Docker Version that this nodes use are: 19.03.14+azure\n>>>   \n>>>   2021/10/08 21:47:41 The vmsize standard_ds11_v2 is not a GPU VM, skipping get GPU count by running nvidia-smi command.\n>>>   2021/10/08 21:47:41 The vmsize standard_ds11_v2 is not a GPU VM, skipping get GPU count by running nvidia-smi command.\n>>>   2021/10/08 21:47:41 sidecar dockerLauncher:docker\n>>>   2021/10/08 21:47:41 sidecarContainerId:f551e8b4e8b32bda4104717a3e852db70609babd4ee3e573d1f6756afb0033bf\n>>>   2021/10/08 21:47:41 Docker Version that this nodes use are: 19.03.14+azure\n>>>   \n>>>   2021/10/08 21:47:41 The vmsize standard_ds11_v2 is not a GPU VM, skipping get GPU count by running nvidia-smi command.\n>>>   2021/10/08 21:47:41 The vmsize standard_ds11_v2 is not a GPU VM, skipping get GPU count by running nvidia-smi command.\n>>>   2021/10/08 21:47:41 Docker logs for 9dc875a6-0c0b-48da-84d6-f6d103842640_DataSidecar\n>>>   [2021-10-08T21:47:31.683630] INFO azureml.sidecar.sidecar: Received task: start. Running on Linux at /mnt/hostfs/mnt/batch/tasks/shared/LS_root/jobs/ict-915-02-jmdl/azureml/9dc875a6-0c0b-48da-84d6-f6d103842640/wd/azureml/9dc875a6-0c0b-48da-84d6-f6d103842640\n>>>   [2021-10-08T21:47:31.687842] INFO azureml.sidecar.sidecar: Started TaskServer. Address: 127.0.0.1, Port: 41167\n>>>   [2021-10-08T21:47:36.035508] INFO azureml.sidecar.task.enter_contexts: Constructing Context Managers\n>>>   [2021-10-08T21:47:36.206] Initialize DatasetContextManager.\n>>>   [2021-10-08T21:47:36.208658] INFO azureml.sidecar.task.enter_contexts: Entering Context Managers\n>>>   [2021-10-08T21:47:36.210679] INFO azureml.sidecar.context_manager_wrapper: Entering context: Dataset\n>>>   fuse: warning: library too old, some operations may not not work\n>>>   [2021-10-08T21:47:40.817417] INFO azureml.sidecar.task.enter_contexts: Entered Context Managers\n>>>   \n>>>   2021/10/08 21:47:41 runSpecialJobTask: job preparation exited with code 0 and err <nil>\n>>>   \n>>>   2021/10/08 21:47:41 runSpecialJobTask->SideCar + : preparation: [2021-10-08T21:47:34.310255] Entering job preparation.\n>>>   2021/10/08 21:47:41 runSpecialJobTask->SideCar + : preparation: [2021-10-08T21:47:35.231743] Starting job preparation.\n>>>   2021/10/08 21:47:41 runSpecialJobTask->SideCar + : preparation: [2021-10-08T21:47:35.231782] Extracting the control code.\n>>>   2021/10/08 21:47:41 runSpecialJobTask->SideCar + : preparation: [2021-10-08T21:47:35.232309] Starting extract_project.\n>>>   2021/10/08 21:47:41 runSpecialJobTask->SideCar + : preparation: [2021-10-08T21:47:35.232378] Starting to extract zip file.\n>>>   2021/10/08 21:47:41 runSpecialJobTask->SideCar + : preparation: [2021-10-08T21:47:35.256920] Finished extracting zip file.\n>>>   2021/10/08 21:47:41 runSpecialJobTask->SideCar + : preparation: [2021-10-08T21:47:35.260744] Using urllib.request Python 3.0 or later\n>>>   2021/10/08 21:47:41 runSpecialJobTask->SideCar + : preparation: [2021-10-08T21:47:35.260809] Start fetching snapshots.\n>>>   2021/10/08 21:47:41 runSpecialJobTask->SideCar + : preparation: [2021-10-08T21:47:35.260866] Start fetching snapshot.\n>>>   2021/10/08 21:47:41 runSpecialJobTask->SideCar + : preparation: [2021-10-08T21:47:35.260883] Retrieving project from snapshot: 12c67a3e-2174-4906-97de-c1712432976e\n>>>   2021/10/08 21:47:41 runSpecialJobTask->SideCar + : preparation: Starting the daemon thread to refresh tokens in background for process with pid = 52\n>>>   2021/10/08 21:47:41 runSpecialJobTask->SideCar + : preparation: [2021-10-08T21:47:35.553826] Finished fetching snapshot.\n>>>   2021/10/08 21:47:41 runSpecialJobTask->SideCar + : preparation: [2021-10-08T21:47:35.553865] Finished fetching snapshots.\n>>>   2021/10/08 21:47:41 runSpecialJobTask->SideCar + : preparation: [2021-10-08T21:47:35.553873] Finished extract_project.\n>>>   2021/10/08 21:47:41 runSpecialJobTask->SideCar + : preparation: [2021-10-08T21:47:35.553964] Finished fetching and extracting the control code.\n>>>   2021/10/08 21:47:41 runSpecialJobTask->SideCar + : preparation: [2021-10-08T21:47:35.561708] Start run_history_prep.\n>>>   2021/10/08 21:47:41 runSpecialJobTask->SideCar + : preparation: [2021-10-08T21:47:35.569167] Job preparation is complete.\n>>>   2021/10/08 21:47:41 runSpecialJobTask->SideCar + : preparation: [2021-10-08T21:47:35.569464] Entering Data Context Managers in Sidecar\n>>>   2021/10/08 21:47:41 runSpecialJobTask->SideCar + : preparation: [2021-10-08T21:47:35.570156] Running Sidecar prep cmd...\n>>>   2021/10/08 21:47:41 runSpecialJobTask->SideCar + : preparation: [2021-10-08T21:47:36.023607] INFO azureml.sidecar.sidecar: Received task: enter_contexts. Running on Linux at /mnt/hostfs/mnt/batch/tasks/shared/LS_root/jobs/ict-915-02-jmdl/azureml/9dc875a6-0c0b-48da-84d6-f6d103842640/wd/azureml/9dc875a6-0c0b-48da-84d6-f6d103842640\n>>>   2021/10/08 21:47:41 runSpecialJobTask->SideCar + : preparation: [2021-10-08T21:47:36.024525] INFO azureml.sidecar.sidecar: Invoking \"enter_contexts\" task with Context Managers: {\"context_managers\": [\"Dataset:context_managers.Datasets\"]}\n>>>   2021/10/08 21:47:41 runSpecialJobTask->SideCar + : preparation: [2021-10-08T21:47:36.214] Enter __enter__ of DatasetContextManager\n>>>   2021/10/08 21:47:41 runSpecialJobTask->SideCar + : preparation: [2021-10-08T21:47:36.215] SDK version: azureml-core==1.33.0.post1 azureml-dataprep==2.22.2. Session id: 28fdc255-1748-4061-b0c5-0d7c73fdc062. Run id: 9dc875a6-0c0b-48da-84d6-f6d103842640.\n>>>   2021/10/08 21:47:41 runSpecialJobTask->SideCar + : preparation: [[[Context Manager output has been redacted.]]]\n>>>   2021/10/08 21:47:41 runSpecialJobTask->SideCar + : preparation: [2021-10-08T21:47:41.384815] Ran Sidecar prep cmd.\n>>>   2021/10/08 21:47:41 runSpecialJobTask->SideCar + : preparation: [2021-10-08T21:47:41.384918] Running Context Managers in Sidecar complete.\n>>>   2021/10/08 21:47:41 DockerSideCarContainerLogs:\n>>>   [2021-10-08T21:47:31.683630] INFO azureml.sidecar.sidecar: Received task: start. Running on Linux at /mnt/hostfs/mnt/batch/tasks/shared/LS_root/jobs/ict-915-02-jmdl/azureml/9dc875a6-0c0b-48da-84d6-f6d103842640/wd/azureml/9dc875a6-0c0b-48da-84d6-f6d103842640\n>>>   [2021-10-08T21:47:31.687842] INFO azureml.sidecar.sidecar: Started TaskServer. Address: 127.0.0.1, Port: 41167\n>>>   [2021-10-08T21:47:36.035508] INFO azureml.sidecar.task.enter_contexts: Constructing Context Managers\n>>>   [2021-10-08T21:47:36.206] Initialize DatasetContextManager.\n>>>   [2021-10-08T21:47:36.208658] INFO azureml.sidecar.task.enter_contexts: Entering Context Managers\n>>>   [2021-10-08T21:47:36.210679] INFO azureml.sidecar.context_manager_wrapper: Entering context: Dataset\n>>>   fuse: warning: library too old, some operations may not not work\n>>>   [2021-10-08T21:47:40.817417] INFO azureml.sidecar.task.enter_contexts: Entered Context Managers\n>>>   \n>>>   2021/10/08 21:47:41 DockerSideCarContainerLogs End\n>>>   2021/10/08 21:47:41 Job preparation command in Sidecar container completed\n>>>   2021/10/08 21:47:41 Sidecar setup completed\n>>>   2021/10/08 21:47:41 Start to pulling docker image: 43960628131b4266b2d2072e89e00bd8.azurecr.io/azureml/azureml_21ec214220b650a356d20fde58334d25\n>>>   2021/10/08 21:47:41 Start pull docker image: 43960628131b4266b2d2072e89e00bd8.azurecr.io\n>>>   2021/10/08 21:47:41 Getting credentials for image 43960628131b4266b2d2072e89e00bd8.azurecr.io/azureml/azureml_21ec214220b650a356d20fde58334d25 with url 43960628131b4266b2d2072e89e00bd8.azurecr.io\n>>>   2021/10/08 21:47:41 Container registry is ACR.\n>>>   2021/10/08 21:47:41 Skip getting ACR Credentials from Identity and will be getting it from EMS\n>>>   2021/10/08 21:47:41 Getting ACR Credentials from EMS for environment experiment_env:1\n>>>   2021/10/08 21:47:41 Requesting XDS for registry details.\n>>>   2021/10/08 21:47:41 Attempt 1 of http call to https://eastus.cert.api.azureml.ms/xdsbatchai/hosttoolapi/subscriptions/448781ce-ecdd-4bf3-91e9-5674666ebec1/resourceGroups/ict-915-02-jmdl/workspaces/ict-915-02-jmdl/clusters/ct-915-02-jmdl/nodes/tvmps_e1613ff6135641c2a128b0ffb7f6b5266031aeab8c73b5f1d1e07eed6cfba49d_d?api-version=2018-02-01\n>>>   2021/10/08 21:47:42 Got container registry details from credentials service for registry address: 43960628131b4266b2d2072e89e00bd8.azurecr.io.\n>>>   2021/10/08 21:47:42 Writing ACR Details to file...\n>>>   2021/10/08 21:47:42 Copying ACR Details file to worker nodes...\n>>>   2021/10/08 21:47:42 Executing 'Copy ACR Details file' on 10.0.0.4\n>>>   2021/10/08 21:47:42 Begin executing 'Copy ACR Details file' task on Node\n>>>   2021/10/08 21:47:42 'Copy ACR Details file' task Node result: succeeded\n>>>   2021/10/08 21:47:42 Copy ACR Details file succeeded on 10.0.0.4. Output: \n>>>   >>>   \n>>>   >>>   \n>>>   2021/10/08 21:47:42 Successfully retrieved ACR Credentials from EMS.\n>>>   2021/10/08 21:47:42 EMS returned 43960628131b4266b2d2072e89e00bd8.azurecr.io for environment experiment_env\n>>>   2021/10/08 21:47:42 Save docker credentials for image 43960628131b4266b2d2072e89e00bd8.azurecr.io/azureml/azureml_21ec214220b650a356d20fde58334d25 in /mnt/batch/tasks/shared/LS_root/jobs/ict-915-02-jmdl/azureml/9dc875a6-0c0b-48da-84d6-f6d103842640/wd/docker_login_A9737C731EF9215F\n>>>   2021/10/08 21:47:42 Start login to the docker registry\n>>>   2021/10/08 21:47:42 Successfully logged into the docker registry.\n>>>   2021/10/08 21:47:42 Start run pull docker image command\n>>>   2021/10/08 21:47:42 Pull docker image succeeded.\n>>>   2021/10/08 21:47:42 Removed docker config dir /mnt/batch/tasks/shared/LS_root/jobs/ict-915-02-jmdl/azureml/9dc875a6-0c0b-48da-84d6-f6d103842640/wd/docker_login_A9737C731EF9215F\n>>>   2021/10/08 21:47:42 Pull docker image time: 615.501923ms\n>>>   \n>>>   2021/10/08 21:47:42 Docker Version that this nodes use are: 19.03.14+azure\n>>>   \n>>>   2021/10/08 21:47:42 The vmsize standard_ds11_v2 is not a GPU VM, skipping get GPU count by running nvidia-smi command.\n>>>   2021/10/08 21:47:42 The vmsize standard_ds11_v2 is not a GPU VM, skipping get GPU count by running nvidia-smi command.\n>>>   2021/10/08 21:47:42 Setting the memory limit for docker container to be 13674 MB\n>>>   2021/10/08 21:47:42 The env variable file size is 42147 bytes\n>>>   2021/10/08 21:47:42 Add parent cgroup '9dc875a6-0c0b-48da-84d6-f6d103842640' to container '9dc875a6-0c0b-48da-84d6-f6d103842640'\n>>>   2021/10/08 21:47:42 /dev/infiniband/uverbs0 found (implying presence of InfiniBand)?: false\n>>>   2021/10/08 21:47:42 Original Arguments: run,--ulimit,memlock=9223372036854775807,--ulimit,nofile=262144:262144,--cap-add,sys_ptrace,--name,9dc875a6-0c0b-48da-84d6-f6d103842640,-v,/mnt/batch/tasks/shared/LS_root/mounts:/mnt/batch/tasks/shared/LS_root/mounts:rshared,-v,/mnt/batch/tasks/shared/LS_root/configs:/mnt/batch/tasks/shared/LS_root/configs,-v,/mnt/batch/tasks/shared/LS_root/shared:/mnt/batch/tasks/shared/LS_root/shared,-v,/mnt/batch/tasks/workitems/f04b5c8c-5c4c-4274-a2fe-c93ca90b5e20/job-1/9dc875a6-0c0b-48da-8_a2cd738a-0b92-4635-9895-740b6ddd8f8d/certs:/mnt/batch/tasks/workitems/f04b5c8c-5c4c-4274-a2fe-c93ca90b5e20/job-1/9dc875a6-0c0b-48da-8_a2cd738a-0b92-4635-9895-740b6ddd8f8d/certs,-v,/mnt/batch/tasks/startup:/mnt/batch/tasks/startup,-m,13674m,-v,/mnt/batch/tasks/shared/LS_root/jobs/ict-915-02-jmdl/azureml/9dc875a6-0c0b-48da-84d6-f6d103842640/wd/azureml/9dc875a6-0c0b-48da-84d6-f6d103842640/azureml_compute_logs:/mnt/batch/tasks/shared/LS_root/jobs/ict-915-02-jmdl/azureml/9dc875a6-0c0b-48da-84d6-f6d103842640/wd/azureml/9dc875a6-0c0b-48da-84d6-f6d103842640/azureml_compute_logs,-v,/mnt/batch/tasks/workitems/f04b5c8c-5c4c-4274-a2fe-c93ca90b5e20/job-1/9dc875a6-0c0b-48da-8_a2cd738a-0b92-4635-9895-740b6ddd8f8d/wd:/mnt/batch/tasks/workitems/f04b5c8c-5c4c-4274-a2fe-c93ca90b5e20/job-1/9dc875a6-0c0b-48da-8_a2cd738a-0b92-4635-9895-740b6ddd8f8d/wd,-v,/mnt/batch/tasks/shared/LS_root/jobs/ict-915-02-jmdl/azureml/9dc875a6-0c0b-48da-84d6-f6d103842640:/mnt/batch/tasks/shared/LS_root/jobs/ict-915-02-jmdl/azureml/9dc875a6-0c0b-48da-84d6-f6d103842640,-v,/mnt/batch/tasks/shared/LS_root/shared/tracing/9dc875a6-0c0b-48da-84d6-f6d103842640/logs/azureml/tracing:/mnt/batch/tasks/shared/LS_root/shared/tracing/9dc875a6-0c0b-48da-84d6-f6d103842640/logs/azureml/tracing,-w,/mnt/batch/tasks/shared/LS_root/jobs/ict-915-02-jmdl/azureml/9dc875a6-0c0b-48da-84d6-f6d103842640/wd,--expose,23,--env-file,/mnt/batch/tasks/shared/LS_root/jobs/ict-915-02-jmdl/azureml/9dc875a6-0c0b-48da-84d6-f6d103842640/config/.batchai.envlist,--cgroup-parent=/9dc875a6-0c0b-48da-84d6-f6d103842640/,--shm-size,2g,-v,/mnt/batch/tasks/shared/LS_root/jobs/ict-915-02-jmdl/azureml/9dc875a6-0c0b-48da-84d6-f6d103842640/wd/input_15c2723e_b60ed111-8436-4f01-b722-3ec17812b6d6:/mnt/batch/tasks/shared/LS_root/jobs/ict-915-02-jmdl/azureml/9dc875a6-0c0b-48da-84d6-f6d103842640/wd/input_15c2723e_b60ed111-8436-4f01-b722-3ec17812b6d6:rslave\n>>>   2021/10/08 21:47:42 the binding /mnt/batch/tasks/shared/LS_root/shared/tracing/9dc875a6-0c0b-48da-84d6-f6d103842640/logs/azureml/tracing:/mnt/batch/tasks/shared/LS_root/shared/tracing/9dc875a6-0c0b-48da-84d6-f6d103842640/logs/azureml/tracing is discarded as we already have /mnt/batch/tasks/shared/LS_root/shared:/mnt/batch/tasks/shared/LS_root/shared \n>>>   2021/10/08 21:47:42 the binding /mnt/batch/tasks/shared/LS_root/jobs/ict-915-02-jmdl/azureml/9dc875a6-0c0b-48da-84d6-f6d103842640/wd/azureml/9dc875a6-0c0b-48da-84d6-f6d103842640/azureml_compute_logs:/mnt/batch/tasks/shared/LS_root/jobs/ict-915-02-jmdl/azureml/9dc875a6-0c0b-48da-84d6-f6d103842640/wd/azureml/9dc875a6-0c0b-48da-84d6-f6d103842640/azureml_compute_logs is discarded as we already have /mnt/batch/tasks/shared/LS_root/jobs/ict-915-02-jmdl/azureml/9dc875a6-0c0b-48da-84d6-f6d103842640:/mnt/batch/tasks/shared/LS_root/jobs/ict-915-02-jmdl/azureml/9dc875a6-0c0b-48da-84d6-f6d103842640 \n>>>   2021/10/08 21:47:42 Updated Arguments: run,--ulimit,memlock=9223372036854775807,--ulimit,nofile=262144:262144,--cap-add,sys_ptrace,--name,9dc875a6-0c0b-48da-84d6-f6d103842640,-m,13674m,-w,/mnt/batch/tasks/shared/LS_root/jobs/ict-915-02-jmdl/azureml/9dc875a6-0c0b-48da-84d6-f6d103842640/wd,--expose,23,--env-file,/mnt/batch/tasks/shared/LS_root/jobs/ict-915-02-jmdl/azureml/9dc875a6-0c0b-48da-84d6-f6d103842640/config/.batchai.envlist,--cgroup-parent=/9dc875a6-0c0b-48da-84d6-f6d103842640/,--shm-size,2g,-v,/mnt/batch/tasks/startup:/mnt/batch/tasks/startup,-v,/mnt/batch/tasks/shared/LS_root/mounts:/mnt/batch/tasks/shared/LS_root/mounts:rshared,-v,/mnt/batch/tasks/shared/LS_root/shared:/mnt/batch/tasks/shared/LS_root/shared,-v,/mnt/batch/tasks/shared/LS_root/configs:/mnt/batch/tasks/shared/LS_root/configs,-v,/mnt/batch/tasks/shared/LS_root/jobs/ict-915-02-jmdl/azureml/9dc875a6-0c0b-48da-84d6-f6d103842640:/mnt/batch/tasks/shared/LS_root/jobs/ict-915-02-jmdl/azureml/9dc875a6-0c0b-48da-84d6-f6d103842640,-v,/mnt/batch/tasks/workitems/f04b5c8c-5c4c-4274-a2fe-c93ca90b5e20/job-1/9dc875a6-0c0b-48da-8_a2cd738a-0b92-4635-9895-740b6ddd8f8d/wd:/mnt/batch/tasks/workitems/f04b5c8c-5c4c-4274-a2fe-c93ca90b5e20/job-1/9dc875a6-0c0b-48da-8_a2cd738a-0b92-4635-9895-740b6ddd8f8d/wd,-v,/mnt/batch/tasks/workitems/f04b5c8c-5c4c-4274-a2fe-c93ca90b5e20/job-1/9dc875a6-0c0b-48da-8_a2cd738a-0b92-4635-9895-740b6ddd8f8d/certs:/mnt/batch/tasks/workitems/f04b5c8c-5c4c-4274-a2fe-c93ca90b5e20/job-1/9dc875a6-0c0b-48da-8_a2cd738a-0b92-4635-9895-740b6ddd8f8d/certs,-v,/mnt/batch/tasks/shared/LS_root/jobs/ict-915-02-jmdl/azureml/9dc875a6-0c0b-48da-84d6-f6d103842640/wd/input_15c2723e_b60ed111-8436-4f01-b722-3ec17812b6d6:/mnt/batch/tasks/shared/LS_root/jobs/ict-915-02-jmdl/azureml/9dc875a6-0c0b-48da-84d6-f6d103842640/wd/input_15c2723e_b60ed111-8436-4f01-b722-3ec17812b6d6:rslave\n>>>   2021/10/08 21:47:42 Running Docker command: docker run --ulimit memlock=9223372036854775807 --ulimit nofile=262144:262144 --cap-add sys_ptrace --name 9dc875a6-0c0b-48da-84d6-f6d103842640 -m 13674m -w /mnt/batch/tasks/shared/LS_root/jobs/ict-915-02-jmdl/azureml/9dc875a6-0c0b-48da-84d6-f6d103842640/wd --expose 23 --env-file /mnt/batch/tasks/shared/LS_root/jobs/ict-915-02-jmdl/azureml/9dc875a6-0c0b-48da-84d6-f6d103842640/config/.batchai.envlist --cgroup-parent=/9dc875a6-0c0b-48da-84d6-f6d103842640/ --shm-size 2g -v /mnt/batch/tasks/startup:/mnt/batch/tasks/startup -v /mnt/batch/tasks/shared/LS_root/mounts:/mnt/batch/tasks/shared/LS_root/mounts:rshared -v /mnt/batch/tasks/shared/LS_root/shared:/mnt/batch/tasks/shared/LS_root/shared -v /mnt/batch/tasks/shared/LS_root/configs:/mnt/batch/tasks/shared/LS_root/configs -v /mnt/batch/tasks/shared/LS_root/jobs/ict-915-02-jmdl/azureml/9dc875a6-0c0b-48da-84d6-f6d103842640:/mnt/batch/tasks/shared/LS_root/jobs/ict-915-02-jmdl/azureml/9dc875a6-0c0b-48da-84d6-f6d103842640 -v /mnt/batch/tasks/workitems/f04b5c8c-5c4c-4274-a2fe-c93ca90b5e20/job-1/9dc875a6-0c0b-48da-8_a2cd738a-0b92-4635-9895-740b6ddd8f8d/wd:/mnt/batch/tasks/workitems/f04b5c8c-5c4c-4274-a2fe-c93ca90b5e20/job-1/9dc875a6-0c0b-48da-8_a2cd738a-0b92-4635-9895-740b6ddd8f8d/wd -v /mnt/batch/tasks/workitems/f04b5c8c-5c4c-4274-a2fe-c93ca90b5e20/job-1/9dc875a6-0c0b-48da-8_a2cd738a-0b92-4635-9895-740b6ddd8f8d/certs:/mnt/batch/tasks/workitems/f04b5c8c-5c4c-4274-a2fe-c93ca90b5e20/job-1/9dc875a6-0c0b-48da-8_a2cd738a-0b92-4635-9895-740b6ddd8f8d/certs -v /mnt/batch/tasks/shared/LS_root/jobs/ict-915-02-jmdl/azureml/9dc875a6-0c0b-48da-84d6-f6d103842640/wd/input_15c2723e_b60ed111-8436-4f01-b722-3ec17812b6d6:/mnt/batch/tasks/shared/LS_root/jobs/ict-915-02-jmdl/azureml/9dc875a6-0c0b-48da-84d6-f6d103842640/wd/input_15c2723e_b60ed111-8436-4f01-b722-3ec17812b6d6:rslave -d -it --privileged --net=host 43960628131b4266b2d2072e89e00bd8.azurecr.io/azureml/azureml_21ec214220b650a356d20fde58334d25\n>>>   2021/10/08 21:47:42 Check if container 9dc875a6-0c0b-48da-84d6-f6d103842640 already exist exited with 0, f551e8b4e8b3\n>>>   \n>>>   \n>>>   2021/10/08 21:47:42 Check if container 9dc875a6-0c0b-48da-84d6-f6d103842640 already exist exited with 0, f551e8b4e8b3\n>>>   \n>>>   \n>>>   2021/10/08 21:47:42 The container 9dc875a6-0c0b-48da-84d6-f6d103842640 already exists, stop and remove it before starting it.\n>>>   2021/10/08 21:47:42 The container 9dc875a6-0c0b-48da-84d6-f6d103842640 already exists, stop and remove it before starting it.\n>>>   2021/10/08 21:47:42 Stopping container 9dc875a6-0c0b-48da-84d6-f6d103842640 exited with 1, Error response from daemon: No such container: 9dc875a6-0c0b-48da-84d6-f6d103842640\n>>>   \n>>>   \n>>>   2021/10/08 21:47:42 Stopping container 9dc875a6-0c0b-48da-84d6-f6d103842640 exited with 1, Error response from daemon: No such container: 9dc875a6-0c0b-48da-84d6-f6d103842640\n>>>   \n>>>   \n>>>   2021/10/08 21:47:42 Removing container 9dc875a6-0c0b-48da-84d6-f6d103842640 exited with 1, Error: No such container: 9dc875a6-0c0b-48da-84d6-f6d103842640\n>>>   \n>>>   \n>>>   2021/10/08 21:47:42 Removing container 9dc875a6-0c0b-48da-84d6-f6d103842640 exited with 1, Error: No such container: 9dc875a6-0c0b-48da-84d6-f6d103842640\n>>>   \n>>>   \n>>>   2021/10/08 21:47:42 Parameters for containerSetup task: useDetonationChamer set to false and sshRequired set to false \n>>>   2021/10/08 21:47:42 Parameters for containerSetup task: useDetonationChamer set to false and sshRequired set to false \n>>>   2021/10/08 21:47:42 containerSetup task cmd: [/mnt/batch/tasks/startup/wd/hosttools -task=containerSetup -traceContext=00-39d40916ab5bc0855578662e5f87db6c-8383d19098721045-01 -sshRequired=false] \n>>>   2021/10/08 21:47:42 containerSetup task cmd: [/mnt/batch/tasks/startup/wd/hosttools -task=containerSetup -traceContext=00-39d40916ab5bc0855578662e5f87db6c-8383d19098721045-01 -sshRequired=false] \n>>>   2021/10/08 21:47:43 Container ssh is not required for job type.\n>>>   2021/10/08 21:47:43 Starting docker container succeeded.\n>>>   2021/10/08 21:47:43 Starting docker container succeeded.\n>>>   2021/10/08 21:47:43 Disk space after starting docker container: 21735MB\n>>>   2021/10/08 21:47:43 SidecarEnabled:: isDetonationChamber: false, useDockerContainer: true\n>>>   2021/10/08 21:47:43 SidecarEnabled:: AmlDatasetContextManagerConfig exists: true\n>>>   2021/10/08 21:47:43 SidecarEnabled:: enabling sidecar due to dataset being present and sidecar is enabled\n>>>   2021/10/08 21:47:43 Attempt 1 of http call to https://eastus.api.azureml.ms/history/v1.0/private/subscriptions/448781ce-ecdd-4bf3-91e9-5674666ebec1/resourceGroups/ict-915-02-jmdl/providers/Microsoft.MachineLearningServices/workspaces/ict-915-02-jmdl/runs/9dc875a6-0c0b-48da-84d6-f6d103842640/spans\n>>>   2021/10/08 21:47:43 Process Exiting with Code:  0\n>>>   2021/10/08 21:47:43 All App Insights Logs was sent successfully or the close timeout of 10 was reached\n>>>   \n2021-10-08T21:47:43Z The vmsize standard_ds11_v2 is not a GPU VM, skipping get GPU count by running nvidia-smi command.\n2021-10-08T21:47:43Z The vmsize standard_ds11_v2 is not a GPU VM, skipping get GPU count by running nvidia-smi command.\n2021-10-08T21:47:43Z 127.0.0.1 slots=2 max-slots=2\n2021-10-08T21:47:43Z launching Custom job\n\nStreaming azureml-logs/75_job_post-tvmps_e1613ff6135641c2a128b0ffb7f6b5266031aeab8c73b5f1d1e07eed6cfba49d_d.txt\n===============================================================================================================\n[2021-10-08T21:47:56.442261] Entering job release\n[2021-10-08T21:47:57.377067] Starting job release\n[2021-10-08T21:47:57.377793] Logging experiment finalizing status in history service.\nStarting the daemon thread to refresh tokens in background for process with pid = 223\n[2021-10-08T21:47:57.378270] job release stage : upload_datastore starting...\n[2021-10-08T21:47:57.393571] Entering context manager injector.[2021-10-08T21:47:57.394008] job release stage : start importing azureml.history._tracking in run_history_release.\n[2021-10-08T21:47:57.394364] job release stage : execute_job_release starting...\n[2021-10-08T21:47:57.397260] job release stage : upload_datastore completed...\n\n[2021-10-08T21:47:57.398080] job release stage : copy_batchai_cached_logs starting...\n[2021-10-08T21:47:57.398868] job release stage : copy_batchai_cached_logs completed...\n[2021-10-08T21:47:57.472044] job release stage : send_run_telemetry starting...\n[2021-10-08T21:47:57.493426] get vm size and vm region successfully.\n[2021-10-08T21:47:57.503720] get compute meta data successfully.\n[2021-10-08T21:47:57.634091] job release stage : execute_job_release completed...\n[2021-10-08T21:47:57.719123] post artifact meta request successfully.\n[2021-10-08T21:47:57.764738] upload compute record artifact successfully.\n[2021-10-08T21:47:57.764824] job release stage : send_run_telemetry completed...\n[2021-10-08T21:47:57.765317] Running in AzureML-Sidecar, starting to exit user context managers...\n[2021-10-08T21:47:57.765860] Running Sidecar release cmd...\n[2021-10-08T21:47:57.779412] INFO azureml.sidecar.sidecar: Received task: exit_contexts. Running on Linux at /mnt/hostfs/mnt/batch/tasks/shared/LS_root/jobs/ict-915-02-jmdl/azureml/9dc875a6-0c0b-48da-84d6-f6d103842640/wd/azureml/9dc875a6-0c0b-48da-84d6-f6d103842640\n[2021-10-08T21:47:57.800] Enter __exit__ of DatasetContextManager\n[2021-10-08T21:47:57.800] Unmounting /mnt/hostfs/mnt/batch/tasks/shared/LS_root/jobs/ict-915-02-jmdl/azureml/9dc875a6-0c0b-48da-84d6-f6d103842640/wd/input_15c2723e_b60ed111-8436-4f01-b722-3ec17812b6d6.\n[2021-10-08T21:47:57.800] Finishing unmounting /mnt/hostfs/mnt/batch/tasks/shared/LS_root/jobs/ict-915-02-jmdl/azureml/9dc875a6-0c0b-48da-84d6-f6d103842640/wd/input_15c2723e_b60ed111-8436-4f01-b722-3ec17812b6d6.\n[2021-10-08T21:47:57.800] Exit __exit__ of DatasetContextManager\n[2021-10-08T21:47:57.800958] Removing absolute paths from host...\n[2021-10-08T21:47:57.807431] INFO azureml.sidecar.task.exit_contexts: Exited Context Managers\n[2021-10-08T21:47:58.464353] Ran Sidecar release cmd.\n[2021-10-08T21:47:58.464462] Job release is complete\n\nStepRun(Train and Register Model) Execution Summary\n====================================================\nStepRun( Train and Register Model ) Status: Finished\n{'runId': '9dc875a6-0c0b-48da-84d6-f6d103842640', 'target': 'CT-915-02-JMDL', 'status': 'Completed', 'startTimeUtc': '2021-10-08T21:47:27.712438Z', 'endTimeUtc': '2021-10-08T21:48:06.01897Z', 'services': {}, 'properties': {'ContentSnapshotId': '12c67a3e-2174-4906-97de-c1712432976e', 'StepType': 'PythonScriptStep', 'ComputeTargetType': 'AmlCompute', 'azureml.moduleid': '7cd18df2-77ac-4ff6-a845-dcdcb8ea291e', 'azureml.runsource': 'azureml.StepRun', 'azureml.nodeid': '987c0531', 'azureml.pipelinerunid': '85184152-a15c-4922-9a90-9754e817a35a', 'azureml.pipeline': '85184152-a15c-4922-9a90-9754e817a35a', 'azureml.pipelineComponent': 'masterescloud', '_azureml.ComputeTargetType': 'amlcompute', 'ProcessInfoFile': 'azureml-logs/process_info.json', 'ProcessStatusFile': 'azureml-logs/process_status.json'}, 'inputDatasets': [{'dataset': {'id': 'b60ed111-8436-4f01-b722-3ec17812b6d6'}, 'consumptionDetails': {'type': 'RunInput', 'inputName': 'input_15c2723e', 'mechanism': 'Mount'}}], 'outputDatasets': [], 'runDefinition': {'script': 'train_diabetes.py', 'command': '', 'useAbsolutePath': False, 'arguments': ['--training-data', 'DatasetConsumptionConfig:input_15c2723e'], 'sourceDirectoryDataStore': None, 'framework': 'Python', 'communicator': 'None', 'target': 'CT-915-02-JMDL', 'dataReferences': {}, 'data': {'input_15c2723e': {'dataLocation': {'dataset': {'id': 'b60ed111-8436-4f01-b722-3ec17812b6d6', 'name': None, 'version': None}, 'dataPath': None, 'uri': None}, 'mechanism': 'Mount', 'environmentVariableName': 'input_15c2723e', 'pathOnCompute': None, 'overwrite': False, 'options': None}}, 'outputData': {}, 'datacaches': [], 'jobName': None, 'maxRunDurationSeconds': None, 'nodeCount': 1, 'instanceTypes': [], 'priority': None, 'credentialPassthrough': False, 'identity': None, 'environment': {'name': 'experiment_env', 'version': '1', 'python': {'interpreterPath': 'python', 'userManagedDependencies': False, 'condaDependencies': {'dependencies': ['python=3.6.2', 'scikit-learn', 'ipykernel', 'matplotlib', 'pandas', 'pip', {'pip': ['azureml-defaults', 'pyarrow']}], 'name': 'azureml_0c5a9aa2def4b3c2501c1f40287a356b'}, 'baseCondaEnvironment': None}, 'environmentVariables': {'EXAMPLE_ENV_VAR': 'EXAMPLE_VALUE'}, 'docker': {'baseImage': 'mcr.microsoft.com/azureml/openmpi3.1.2-ubuntu18.04:20210806.v1', 'platform': {'os': 'Linux', 'architecture': 'amd64'}, 'baseDockerfile': None, 'baseImageRegistry': {'address': None, 'username': None, 'password': None}, 'enabled': False, 'arguments': []}, 'spark': {'repositories': [], 'packages': [], 'precachePackages': True}, 'inferencingStackVersion': None}, 'history': {'outputCollection': True, 'directoriesToWatch': ['logs'], 'enableMLflowTracking': True, 'snapshotProject': True}, 'spark': {'configuration': {'spark.app.name': 'Azure ML Experiment', 'spark.yarn.maxAppAttempts': '1'}}, 'parallelTask': {'maxRetriesPerWorker': 0, 'workerCountPerNode': 1, 'terminalExitCodes': None, 'configuration': {}}, 'amlCompute': {'name': None, 'vmSize': None, 'retainCluster': False, 'clusterMaxNodeCount': 1, 'location': None}, 'aiSuperComputer': {'instanceType': 'AISupercomputer.D2', 'imageVersion': 'pytorch-1.7.0', 'location': None, 'aiSuperComputerStorageData': None, 'interactive': False, 'scalePolicy': None, 'virtualClusterArmId': None, 'tensorboardLogDirectory': None, 'sshPublicKey': None, 'enableAzmlInt': True, 'priority': 'Medium', 'slaTier': 'Standard', 'userAlias': None}, 'kubernetesCompute': {'instanceType': None}, 'tensorflow': {'workerCount': 1, 'parameterServerCount': 1}, 'mpi': {'processCountPerNode': 1}, 'pyTorch': {'communicationBackend': 'nccl', 'processCount': None}, 'hdi': {'yarnDeployMode': 'Cluster'}, 'containerInstance': {'region': None, 'cpuCores': 2.0, 'memoryGb': 3.5}, 'exposedPorts': None, 'docker': {'useDocker': False, 'sharedVolumes': True, 'shmSize': '2g', 'arguments': []}, 'cmk8sCompute': {'configuration': {}}, 'commandReturnCodeConfig': {'returnCode': 'Zero', 'successfulReturnCodes': []}, 'environmentVariables': {}, 'applicationEndpoints': {}, 'parameters': [], 'dataBricks': {'workers': 0, 'minimumWorkerCount': 0, 'maxMumWorkerCount': 0, 'sparkVersion': '4.0.x-scala2.11', 'nodeTypeId': 'Standard_D3_v2', 'sparkConf': {}, 'sparkEnvVars': {}, 'instancePoolId': None, 'timeoutSeconds': 0, 'linkedADBWorkspaceMetadata': None, 'databrickResourceId': None}}, 'logFiles': {'azureml-logs/55_azureml-execution-tvmps_e1613ff6135641c2a128b0ffb7f6b5266031aeab8c73b5f1d1e07eed6cfba49d_d.txt': 'https://ict91502jmdl5971809827.blob.core.windows.net/azureml/ExperimentRun/dcid.9dc875a6-0c0b-48da-84d6-f6d103842640/azureml-logs/55_azureml-execution-tvmps_e1613ff6135641c2a128b0ffb7f6b5266031aeab8c73b5f1d1e07eed6cfba49d_d.txt?sv=2019-07-07&sr=b&sig=qeGUmLy5skiV%2Fmku2LO2idcrQKaw1HEasUDPQvhfVF4%3D&skoid=65509533-6487-43e3-a9e5-9135310d21ed&sktid=669832bc-1c49-401d-84ca-5fe95035ead2&skt=2021-10-08T20%3A20%3A47Z&ske=2021-10-10T04%3A30%3A47Z&sks=b&skv=2019-07-07&st=2021-10-08T21%3A38%3A00Z&se=2021-10-09T05%3A48%3A00Z&sp=r', 'azureml-logs/65_job_prep-tvmps_e1613ff6135641c2a128b0ffb7f6b5266031aeab8c73b5f1d1e07eed6cfba49d_d.txt': 'https://ict91502jmdl5971809827.blob.core.windows.net/azureml/ExperimentRun/dcid.9dc875a6-0c0b-48da-84d6-f6d103842640/azureml-logs/65_job_prep-tvmps_e1613ff6135641c2a128b0ffb7f6b5266031aeab8c73b5f1d1e07eed6cfba49d_d.txt?sv=2019-07-07&sr=b&sig=MmGU3unFHv4MG0jEWYiBO1ug5CSAuzyQf1%2F6ZshNMZ4%3D&skoid=65509533-6487-43e3-a9e5-9135310d21ed&sktid=669832bc-1c49-401d-84ca-5fe95035ead2&skt=2021-10-08T20%3A20%3A47Z&ske=2021-10-10T04%3A30%3A47Z&sks=b&skv=2019-07-07&st=2021-10-08T21%3A38%3A00Z&se=2021-10-09T05%3A48%3A00Z&sp=r', 'azureml-logs/70_driver_log.txt': 'https://ict91502jmdl5971809827.blob.core.windows.net/azureml/ExperimentRun/dcid.9dc875a6-0c0b-48da-84d6-f6d103842640/azureml-logs/70_driver_log.txt?sv=2019-07-07&sr=b&sig=btw6edYE1D2HIew%2Be1bG6O2%2FcSdSq6e%2F8pxWMTevq7Y%3D&skoid=65509533-6487-43e3-a9e5-9135310d21ed&sktid=669832bc-1c49-401d-84ca-5fe95035ead2&skt=2021-10-08T20%3A20%3A47Z&ske=2021-10-10T04%3A30%3A47Z&sks=b&skv=2019-07-07&st=2021-10-08T21%3A38%3A00Z&se=2021-10-09T05%3A48%3A00Z&sp=r', 'azureml-logs/75_job_post-tvmps_e1613ff6135641c2a128b0ffb7f6b5266031aeab8c73b5f1d1e07eed6cfba49d_d.txt': 'https://ict91502jmdl5971809827.blob.core.windows.net/azureml/ExperimentRun/dcid.9dc875a6-0c0b-48da-84d6-f6d103842640/azureml-logs/75_job_post-tvmps_e1613ff6135641c2a128b0ffb7f6b5266031aeab8c73b5f1d1e07eed6cfba49d_d.txt?sv=2019-07-07&sr=b&sig=RO4RrsS7ijpv%2Fazfk%2B6dUETixrNdIR5gYJxUt%2B0%2B2zA%3D&skoid=65509533-6487-43e3-a9e5-9135310d21ed&sktid=669832bc-1c49-401d-84ca-5fe95035ead2&skt=2021-10-08T20%3A20%3A47Z&ske=2021-10-10T04%3A30%3A47Z&sks=b&skv=2019-07-07&st=2021-10-08T21%3A38%3A00Z&se=2021-10-09T05%3A48%3A00Z&sp=r', 'azureml-logs/process_info.json': 'https://ict91502jmdl5971809827.blob.core.windows.net/azureml/ExperimentRun/dcid.9dc875a6-0c0b-48da-84d6-f6d103842640/azureml-logs/process_info.json?sv=2019-07-07&sr=b&sig=A29XncM0oIvOdyIyCTRkAuG5iC7tPlJQK%2Bze26PedUs%3D&skoid=65509533-6487-43e3-a9e5-9135310d21ed&sktid=669832bc-1c49-401d-84ca-5fe95035ead2&skt=2021-10-08T20%3A20%3A47Z&ske=2021-10-10T04%3A30%3A47Z&sks=b&skv=2019-07-07&st=2021-10-08T21%3A38%3A00Z&se=2021-10-09T05%3A48%3A00Z&sp=r', 'azureml-logs/process_status.json': 'https://ict91502jmdl5971809827.blob.core.windows.net/azureml/ExperimentRun/dcid.9dc875a6-0c0b-48da-84d6-f6d103842640/azureml-logs/process_status.json?sv=2019-07-07&sr=b&sig=ApIlFRA82%2Ba5KcZEMxwg5eGoW52lXMrBAQQLsfuFDN4%3D&skoid=65509533-6487-43e3-a9e5-9135310d21ed&sktid=669832bc-1c49-401d-84ca-5fe95035ead2&skt=2021-10-08T20%3A20%3A47Z&ske=2021-10-10T04%3A30%3A47Z&sks=b&skv=2019-07-07&st=2021-10-08T21%3A38%3A00Z&se=2021-10-09T05%3A48%3A00Z&sp=r', 'logs/azureml/70_azureml.log': 'https://ict91502jmdl5971809827.blob.core.windows.net/azureml/ExperimentRun/dcid.9dc875a6-0c0b-48da-84d6-f6d103842640/logs/azureml/70_azureml.log?sv=2019-07-07&sr=b&sig=2GV2HG5ROUHUEnpstWdKkgly6OSbqfySvFfASROv3F4%3D&skoid=65509533-6487-43e3-a9e5-9135310d21ed&sktid=669832bc-1c49-401d-84ca-5fe95035ead2&skt=2021-10-08T01%3A16%3A34Z&ske=2021-10-09T09%3A26%3A34Z&sks=b&skv=2019-07-07&st=2021-10-08T21%3A38%3A00Z&se=2021-10-09T05%3A48%3A00Z&sp=r', 'logs/azureml/dataprep/backgroundProcess.log': 'https://ict91502jmdl5971809827.blob.core.windows.net/azureml/ExperimentRun/dcid.9dc875a6-0c0b-48da-84d6-f6d103842640/logs/azureml/dataprep/backgroundProcess.log?sv=2019-07-07&sr=b&sig=3JlfalWHny%2Fl1P6Pb%2BgT9L1DI3Pckvvybg4I6i9xw4c%3D&skoid=65509533-6487-43e3-a9e5-9135310d21ed&sktid=669832bc-1c49-401d-84ca-5fe95035ead2&skt=2021-10-08T01%3A16%3A34Z&ske=2021-10-09T09%3A26%3A34Z&sks=b&skv=2019-07-07&st=2021-10-08T21%3A38%3A00Z&se=2021-10-09T05%3A48%3A00Z&sp=r', 'logs/azureml/dataprep/backgroundProcess_Telemetry.log': 'https://ict91502jmdl5971809827.blob.core.windows.net/azureml/ExperimentRun/dcid.9dc875a6-0c0b-48da-84d6-f6d103842640/logs/azureml/dataprep/backgroundProcess_Telemetry.log?sv=2019-07-07&sr=b&sig=K8UsbD9U0nhQxdJ4O3iu8fQmWrOk%2BENbQI73q8UX%2FQs%3D&skoid=65509533-6487-43e3-a9e5-9135310d21ed&sktid=669832bc-1c49-401d-84ca-5fe95035ead2&skt=2021-10-08T01%3A16%3A34Z&ske=2021-10-09T09%3A26%3A34Z&sks=b&skv=2019-07-07&st=2021-10-08T21%3A38%3A00Z&se=2021-10-09T05%3A48%3A00Z&sp=r', 'logs/azureml/executionlogs.txt': 'https://ict91502jmdl5971809827.blob.core.windows.net/azureml/ExperimentRun/dcid.9dc875a6-0c0b-48da-84d6-f6d103842640/logs/azureml/executionlogs.txt?sv=2019-07-07&sr=b&sig=l%2BWl8COg%2B%2BIRap0VqPZdOMYHUtntuuhUzhjXuADs6hQ%3D&skoid=65509533-6487-43e3-a9e5-9135310d21ed&sktid=669832bc-1c49-401d-84ca-5fe95035ead2&skt=2021-10-08T01%3A16%3A34Z&ske=2021-10-09T09%3A26%3A34Z&sks=b&skv=2019-07-07&st=2021-10-08T21%3A38%3A00Z&se=2021-10-09T05%3A48%3A00Z&sp=r', 'logs/azureml/job_prep_azureml.log': 'https://ict91502jmdl5971809827.blob.core.windows.net/azureml/ExperimentRun/dcid.9dc875a6-0c0b-48da-84d6-f6d103842640/logs/azureml/job_prep_azureml.log?sv=2019-07-07&sr=b&sig=QafbjKN8IR0jaMRMjCEqeDYfdhlzyFgbs5yNCpq4cuI%3D&skoid=65509533-6487-43e3-a9e5-9135310d21ed&sktid=669832bc-1c49-401d-84ca-5fe95035ead2&skt=2021-10-08T01%3A16%3A34Z&ske=2021-10-09T09%3A26%3A34Z&sks=b&skv=2019-07-07&st=2021-10-08T21%3A38%3A00Z&se=2021-10-09T05%3A48%3A00Z&sp=r', 'logs/azureml/job_release_azureml.log': 'https://ict91502jmdl5971809827.blob.core.windows.net/azureml/ExperimentRun/dcid.9dc875a6-0c0b-48da-84d6-f6d103842640/logs/azureml/job_release_azureml.log?sv=2019-07-07&sr=b&sig=Fwbr3voTFh53luzIpvj8u89qcjtR%2BJlzrfSJgbv3KYQ%3D&skoid=65509533-6487-43e3-a9e5-9135310d21ed&sktid=669832bc-1c49-401d-84ca-5fe95035ead2&skt=2021-10-08T01%3A16%3A34Z&ske=2021-10-09T09%3A26%3A34Z&sks=b&skv=2019-07-07&st=2021-10-08T21%3A38%3A00Z&se=2021-10-09T05%3A48%3A00Z&sp=r', 'logs/azureml/sidecar/tvmps_e1613ff6135641c2a128b0ffb7f6b5266031aeab8c73b5f1d1e07eed6cfba49d_d/all.log': 'https://ict91502jmdl5971809827.blob.core.windows.net/azureml/ExperimentRun/dcid.9dc875a6-0c0b-48da-84d6-f6d103842640/logs/azureml/sidecar/tvmps_e1613ff6135641c2a128b0ffb7f6b5266031aeab8c73b5f1d1e07eed6cfba49d_d/all.log?sv=2019-07-07&sr=b&sig=fmxpS%2BEmoNtb5adPEcrhJmn3pXRSIa5yVmLqtnivRgc%3D&skoid=65509533-6487-43e3-a9e5-9135310d21ed&sktid=669832bc-1c49-401d-84ca-5fe95035ead2&skt=2021-10-08T01%3A16%3A34Z&ske=2021-10-09T09%3A26%3A34Z&sks=b&skv=2019-07-07&st=2021-10-08T21%3A38%3A00Z&se=2021-10-09T05%3A48%3A00Z&sp=r', 'logs/azureml/sidecar/tvmps_e1613ff6135641c2a128b0ffb7f6b5266031aeab8c73b5f1d1e07eed6cfba49d_d/task.enter_contexts.log': 'https://ict91502jmdl5971809827.blob.core.windows.net/azureml/ExperimentRun/dcid.9dc875a6-0c0b-48da-84d6-f6d103842640/logs/azureml/sidecar/tvmps_e1613ff6135641c2a128b0ffb7f6b5266031aeab8c73b5f1d1e07eed6cfba49d_d/task.enter_contexts.log?sv=2019-07-07&sr=b&sig=1pTdwNKJFLDR%2FKK9kqd%2FU9w1CCTSwCvnL%2BcAA3hPhEQ%3D&skoid=65509533-6487-43e3-a9e5-9135310d21ed&sktid=669832bc-1c49-401d-84ca-5fe95035ead2&skt=2021-10-08T01%3A16%3A34Z&ske=2021-10-09T09%3A26%3A34Z&sks=b&skv=2019-07-07&st=2021-10-08T21%3A38%3A00Z&se=2021-10-09T05%3A48%3A00Z&sp=r', 'logs/azureml/sidecar/tvmps_e1613ff6135641c2a128b0ffb7f6b5266031aeab8c73b5f1d1e07eed6cfba49d_d/task.exit_contexts.log': 'https://ict91502jmdl5971809827.blob.core.windows.net/azureml/ExperimentRun/dcid.9dc875a6-0c0b-48da-84d6-f6d103842640/logs/azureml/sidecar/tvmps_e1613ff6135641c2a128b0ffb7f6b5266031aeab8c73b5f1d1e07eed6cfba49d_d/task.exit_contexts.log?sv=2019-07-07&sr=b&sig=TILKfcn8apazRYH%2FowiffEWBJ7aQu0Ek3qhPa5X5%2FzI%3D&skoid=65509533-6487-43e3-a9e5-9135310d21ed&sktid=669832bc-1c49-401d-84ca-5fe95035ead2&skt=2021-10-08T01%3A16%3A34Z&ske=2021-10-09T09%3A26%3A34Z&sks=b&skv=2019-07-07&st=2021-10-08T21%3A38%3A00Z&se=2021-10-09T05%3A48%3A00Z&sp=r', 'logs/azureml/stderrlogs.txt': 'https://ict91502jmdl5971809827.blob.core.windows.net/azureml/ExperimentRun/dcid.9dc875a6-0c0b-48da-84d6-f6d103842640/logs/azureml/stderrlogs.txt?sv=2019-07-07&sr=b&sig=jcPX6gOehQRCOYEij9YGl2OeX7cgKtVWhsnFvr83V58%3D&skoid=65509533-6487-43e3-a9e5-9135310d21ed&sktid=669832bc-1c49-401d-84ca-5fe95035ead2&skt=2021-10-08T01%3A16%3A34Z&ske=2021-10-09T09%3A26%3A34Z&sks=b&skv=2019-07-07&st=2021-10-08T21%3A38%3A00Z&se=2021-10-09T05%3A48%3A00Z&sp=r', 'logs/azureml/stdoutlogs.txt': 'https://ict91502jmdl5971809827.blob.core.windows.net/azureml/ExperimentRun/dcid.9dc875a6-0c0b-48da-84d6-f6d103842640/logs/azureml/stdoutlogs.txt?sv=2019-07-07&sr=b&sig=7RBPdLiKzRRJ50SyV1gjhxApgJ5YkHeHC1s1P3aTk4k%3D&skoid=65509533-6487-43e3-a9e5-9135310d21ed&sktid=669832bc-1c49-401d-84ca-5fe95035ead2&skt=2021-10-08T01%3A16%3A34Z&ske=2021-10-09T09%3A26%3A34Z&sks=b&skv=2019-07-07&st=2021-10-08T21%3A38%3A00Z&se=2021-10-09T05%3A48%3A00Z&sp=r'}, 'submittedBy': 'Francisco Javier Medel Medina'}\n\n\n\nPipelineRun Execution Summary\n==============================\nPipelineRun Status: Finished\n{'runId': '85184152-a15c-4922-9a90-9754e817a35a', 'status': 'Completed', 'startTimeUtc': '2021-10-08T21:42:22.247699Z', 'endTimeUtc': '2021-10-08T21:48:07.49659Z', 'services': {}, 'properties': {'azureml.runsource': 'azureml.PipelineRun', 'runSource': 'SDK', 'runType': 'SDK', 'azureml.parameters': '{}', 'azureml.pipelineComponent': 'pipelinerun'}, 'inputDatasets': [], 'outputDatasets': [], 'logFiles': {'logs/azureml/executionlogs.txt': 'https://ict91502jmdl5971809827.blob.core.windows.net/azureml/ExperimentRun/dcid.85184152-a15c-4922-9a90-9754e817a35a/logs/azureml/executionlogs.txt?sv=2019-07-07&sr=b&sig=nHPozAhIF9fJWffV2atTd67l520GKuJR%2FmZtFhZ5ZxA%3D&skoid=65509533-6487-43e3-a9e5-9135310d21ed&sktid=669832bc-1c49-401d-84ca-5fe95035ead2&skt=2021-10-08T20%3A51%3A03Z&ske=2021-10-10T05%3A01%3A03Z&sks=b&skv=2019-07-07&st=2021-10-08T21%3A32%3A46Z&se=2021-10-09T05%3A42%3A46Z&sp=r', 'logs/azureml/stderrlogs.txt': 'https://ict91502jmdl5971809827.blob.core.windows.net/azureml/ExperimentRun/dcid.85184152-a15c-4922-9a90-9754e817a35a/logs/azureml/stderrlogs.txt?sv=2019-07-07&sr=b&sig=nHAPIFi0ujeMWKZqdFdWeE3GPOcjuhe%2BvuZ9oLVqTtk%3D&skoid=65509533-6487-43e3-a9e5-9135310d21ed&sktid=669832bc-1c49-401d-84ca-5fe95035ead2&skt=2021-10-08T20%3A51%3A03Z&ske=2021-10-10T05%3A01%3A03Z&sks=b&skv=2019-07-07&st=2021-10-08T21%3A32%3A46Z&se=2021-10-09T05%3A42%3A46Z&sp=r', 'logs/azureml/stdoutlogs.txt': 'https://ict91502jmdl5971809827.blob.core.windows.net/azureml/ExperimentRun/dcid.85184152-a15c-4922-9a90-9754e817a35a/logs/azureml/stdoutlogs.txt?sv=2019-07-07&sr=b&sig=H6MmNkcSmt%2BJu2AAc7PPXYEXDlXf26OLa4K%2FsXY6DnU%3D&skoid=65509533-6487-43e3-a9e5-9135310d21ed&sktid=669832bc-1c49-401d-84ca-5fe95035ead2&skt=2021-10-08T20%3A51%3A03Z&ske=2021-10-10T05%3A01%3A03Z&sks=b&skv=2019-07-07&st=2021-10-08T21%3A32%3A46Z&se=2021-10-09T05%3A42%3A46Z&sp=r'}, 'submittedBy': 'Francisco Javier Medel Medina'}\n\n"
        },
        {
          "output_type": "execute_result",
          "execution_count": 10,
          "data": {
            "text/plain": "'Finished'"
          },
          "metadata": {}
        }
      ],
      "execution_count": 10,
      "metadata": {
        "scrolled": false,
        "gather": {
          "logged": 1633729689488
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "A graphical representation of the pipeline experiment will be displayed in the widget as it runs. Keep an eye on the kernel indicator at the top right of the page, when it turns from **&#9899;** to **&#9711;**, the code has finished running. You can also monitor pipeline runs in the **Experiments** page in [Azure Machine Learning studio](https://ml.azure.com).\n",
        "\n",
        "When the pipeline has finished, you can examine the metrics recorded by it's child runs."
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "for run in pipeline_run.get_children():\n",
        "    print(run.name, ':')\n",
        "    metrics = run.get_metrics()\n",
        "    for metric_name in metrics:\n",
        "        print('\\t',metric_name, \":\", metrics[metric_name])"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "Train and Register Model :\n\t Accuracy : 0.9006666666666666\n\t AUC : 0.8857524015639696\n\t ROC : aml://artifactId/ExperimentRun/dcid.9dc875a6-0c0b-48da-84d6-f6d103842640/ROC_1633729666.png\nPrepare Data :\n\t raw_rows : 15000\n\t processed_rows : 15000\n"
        }
      ],
      "execution_count": 11,
      "metadata": {
        "gather": {
          "logged": 1633729934518
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Assuming the pipeline was successful, a new model should be registered with a *Training context* tag indicating it was trained in a pipeline. Run the following code to verify this."
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "from azureml.core import Model\n",
        "\n",
        "for model in Model.list(ws):\n",
        "    print(model.name, 'version:', model.version)\n",
        "    for tag_name in model.tags:\n",
        "        tag = model.tags[tag_name]\n",
        "        print ('\\t',tag_name, ':', tag)\n",
        "    for prop_name in model.properties:\n",
        "        prop = model.properties[prop_name]\n",
        "        print ('\\t',prop_name, ':', prop)\n",
        "    print('\\n')"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "diabetes_model version: 6\n\t Training context : Pipeline\n\t AUC : 0.8857524015639696\n\t Accuracy : 0.9006666666666666\n\n\ndiabetes_model version: 5\n\t Training context : Compute cluster\n\t AUC : 0.8829290099725624\n\t Accuracy : 0.898\n\n\ndiabetes_model version: 4\n\t Training context : File dataset\n\t AUC : 0.8568743524381947\n\t Accuracy : 0.7891111111111111\n\n\ndiabetes_model version: 3\n\t Training context : Tabular dataset\n\t AUC : 0.8568509052814499\n\t Accuracy : 0.7891111111111111\n\n\ndiabetes_model version: 2\n\t Training context : Parameterized script\n\t AUC : 0.8483103636996865\n\t Accuracy : 0.7746666666666666\n\n\ndiabetes_model version: 1\n\t Training context : Script\n\t AUC : 0.8483377282451863\n\t Accuracy : 0.774\n\n\nAutoMLc4345bc5e0 version: 1\n\n\n"
        }
      ],
      "execution_count": 12,
      "metadata": {
        "gather": {
          "logged": 1633730136105
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Publish the pipeline\n",
        "\n",
        "After you've created and tested a pipeline, you can publish it as a REST service."
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "# Publish the pipeline from the run\n",
        "published_pipeline = pipeline_run.publish_pipeline(\n",
        "    name=\"diabetes-training-pipeline\", description=\"Trains diabetes model\", version=\"1.0\")\n",
        "\n",
        "published_pipeline"
      ],
      "outputs": [
        {
          "output_type": "execute_result",
          "execution_count": 14,
          "data": {
            "text/plain": "Pipeline(Name: diabetes-training-pipeline,\nId: 2f4afe6d-247b-447d-a0d2-1d0e891bc8ba,\nStatus: Active,\nEndpoint: https://eastus.api.azureml.ms/pipelines/v1.0/subscriptions/448781ce-ecdd-4bf3-91e9-5674666ebec1/resourceGroups/ict-915-02-jmdl/providers/Microsoft.MachineLearningServices/workspaces/ict-915-02-jmdl/PipelineRuns/PipelineSubmit/2f4afe6d-247b-447d-a0d2-1d0e891bc8ba)",
            "text/html": "<table style=\"width:100%\"><tr><th>Name</th><th>Id</th><th>Status</th><th>Endpoint</th></tr><tr><td>diabetes-training-pipeline</td><td><a href=\"https://ml.azure.com/pipelines/2f4afe6d-247b-447d-a0d2-1d0e891bc8ba?wsid=/subscriptions/448781ce-ecdd-4bf3-91e9-5674666ebec1/resourcegroups/ict-915-02-jmdl/workspaces/ict-915-02-jmdl\" target=\"_blank\" rel=\"noopener\">2f4afe6d-247b-447d-a0d2-1d0e891bc8ba</a></td><td>Active</td><td><a href=\"https://eastus.api.azureml.ms/pipelines/v1.0/subscriptions/448781ce-ecdd-4bf3-91e9-5674666ebec1/resourceGroups/ict-915-02-jmdl/providers/Microsoft.MachineLearningServices/workspaces/ict-915-02-jmdl/PipelineRuns/PipelineSubmit/2f4afe6d-247b-447d-a0d2-1d0e891bc8ba\" target=\"_blank\" rel=\"noopener\">REST Endpoint</a></td></tr></table>"
          },
          "metadata": {}
        }
      ],
      "execution_count": 14,
      "metadata": {
        "gather": {
          "logged": 1633730502967
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Note that the published pipeline has an endpoint, which you can see in the **Endpoints** page (on the **Pipeline Endpoints** tab) in [Azure Machine Learning studio](https://ml.azure.com). You can also find its URI as a property of the published pipeline object:"
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "rest_endpoint = published_pipeline.endpoint\n",
        "print(rest_endpoint)"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "https://eastus.api.azureml.ms/pipelines/v1.0/subscriptions/448781ce-ecdd-4bf3-91e9-5674666ebec1/resourceGroups/ict-915-02-jmdl/providers/Microsoft.MachineLearningServices/workspaces/ict-915-02-jmdl/PipelineRuns/PipelineSubmit/2f4afe6d-247b-447d-a0d2-1d0e891bc8ba\n"
        }
      ],
      "execution_count": 15,
      "metadata": {
        "gather": {
          "logged": 1633730695010
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Call the pipeline endpoint\n",
        "\n",
        "To use the endpoint, client applications need to make a REST call over HTTP. This request must be authenticated, so an authorization header is required. A real application would require a service principal with which to be authenticated, but to test this out, we'll use the authorization header from your current connection to your Azure workspace, which you can get using the following code:"
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "from azureml.core.authentication import InteractiveLoginAuthentication\n",
        "\n",
        "interactive_auth = InteractiveLoginAuthentication()\n",
        "auth_header = interactive_auth.get_authentication_header()\n",
        "print(\"Authentication header ready.\")"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "Authentication header ready.\n"
        }
      ],
      "execution_count": 16,
      "metadata": {
        "gather": {
          "logged": 1633730790501
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Now we're ready to call the REST interface. The pipeline runs asynchronously, so we'll get an identifier back, which we can use to track the pipeline experiment as it runs:"
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "import requests\n",
        "\n",
        "experiment_name = 'mslearn-diabetes-pipeline'\n",
        "\n",
        "rest_endpoint = published_pipeline.endpoint\n",
        "response = requests.post(rest_endpoint, \n",
        "                         headers=auth_header, \n",
        "                         json={\"ExperimentName\": experiment_name})\n",
        "run_id = response.json()[\"Id\"]\n",
        "run_id"
      ],
      "outputs": [
        {
          "output_type": "execute_result",
          "execution_count": 17,
          "data": {
            "text/plain": "'fbe60212-32a9-4f86-837d-d2b665ae2e76'"
          },
          "metadata": {}
        }
      ],
      "execution_count": 17,
      "metadata": {
        "gather": {
          "logged": 1633730902701
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Since you have the run ID, you can use it to wait for the run to complete.\n",
        "\n",
        "> **Note**: The pipeline should complete quickly, because each step was configured to allow output reuse. This was done primarily for convenience and to save time in this course. In reality, you'd likely want the first step to run every time in case the data has changed, and trigger the subsequent steps only if the output from step one changes."
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "from azureml.pipeline.core.run import PipelineRun\n",
        "\n",
        "published_pipeline_run = PipelineRun(ws.experiments[experiment_name], run_id)\n",
        "published_pipeline_run.wait_for_completion(show_output=True)"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "PipelineRunId: fbe60212-32a9-4f86-837d-d2b665ae2e76\nLink to Azure Machine Learning Portal: https://ml.azure.com/runs/fbe60212-32a9-4f86-837d-d2b665ae2e76?wsid=/subscriptions/448781ce-ecdd-4bf3-91e9-5674666ebec1/resourcegroups/ict-915-02-jmdl/workspaces/ict-915-02-jmdl&tid=669832bc-1c49-401d-84ca-5fe95035ead2\n\nPipelineRun Execution Summary\n==============================\nPipelineRun Status: Finished\n{'runId': 'fbe60212-32a9-4f86-837d-d2b665ae2e76', 'status': 'Completed', 'startTimeUtc': '2021-10-08T22:08:23.813609Z', 'endTimeUtc': '2021-10-08T22:08:26.167544Z', 'services': {}, 'properties': {'azureml.runsource': 'azureml.PipelineRun', 'runSource': 'Unavailable', 'runType': 'HTTP', 'azureml.parameters': '{}', 'azureml.pipelineComponent': 'pipelinerun', 'azureml.pipelineid': '2f4afe6d-247b-447d-a0d2-1d0e891bc8ba'}, 'inputDatasets': [], 'outputDatasets': [], 'logFiles': {'logs/azureml/executionlogs.txt': 'https://ict91502jmdl5971809827.blob.core.windows.net/azureml/ExperimentRun/dcid.fbe60212-32a9-4f86-837d-d2b665ae2e76/logs/azureml/executionlogs.txt?sv=2019-07-07&sr=b&sig=TkpoKMXuJYW4iuT5k42vLryjeLl2210JWad7r1px6fk%3D&skoid=65509533-6487-43e3-a9e5-9135310d21ed&sktid=669832bc-1c49-401d-84ca-5fe95035ead2&skt=2021-10-08T20%3A32%3A47Z&ske=2021-10-10T04%3A42%3A47Z&sks=b&skv=2019-07-07&st=2021-10-08T21%3A58%3A48Z&se=2021-10-09T06%3A08%3A48Z&sp=r', 'logs/azureml/stderrlogs.txt': 'https://ict91502jmdl5971809827.blob.core.windows.net/azureml/ExperimentRun/dcid.fbe60212-32a9-4f86-837d-d2b665ae2e76/logs/azureml/stderrlogs.txt?sv=2019-07-07&sr=b&sig=5AxZWWMWXoTLuppiSwx8LwoXe5UOb8nVU3pDdy1DA9E%3D&skoid=65509533-6487-43e3-a9e5-9135310d21ed&sktid=669832bc-1c49-401d-84ca-5fe95035ead2&skt=2021-10-08T20%3A32%3A47Z&ske=2021-10-10T04%3A42%3A47Z&sks=b&skv=2019-07-07&st=2021-10-08T21%3A58%3A48Z&se=2021-10-09T06%3A08%3A48Z&sp=r', 'logs/azureml/stdoutlogs.txt': 'https://ict91502jmdl5971809827.blob.core.windows.net/azureml/ExperimentRun/dcid.fbe60212-32a9-4f86-837d-d2b665ae2e76/logs/azureml/stdoutlogs.txt?sv=2019-07-07&sr=b&sig=LvzCmvJHKdrKnUGL1fTSor%2BBQ8AUaR%2FzwH9co4bWMSE%3D&skoid=65509533-6487-43e3-a9e5-9135310d21ed&sktid=669832bc-1c49-401d-84ca-5fe95035ead2&skt=2021-10-08T20%3A32%3A47Z&ske=2021-10-10T04%3A42%3A47Z&sks=b&skv=2019-07-07&st=2021-10-08T21%3A58%3A48Z&se=2021-10-09T06%3A08%3A48Z&sp=r'}, 'submittedBy': 'Francisco Javier Medel Medina'}\n\n"
        },
        {
          "output_type": "execute_result",
          "execution_count": 18,
          "data": {
            "text/plain": "'Finished'"
          },
          "metadata": {}
        }
      ],
      "execution_count": 18,
      "metadata": {
        "gather": {
          "logged": 1633730977701
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Schedule the Pipeline\n",
        "\n",
        "Suppose the clinic for the diabetes patients collects new data each week, and adds it to the dataset. You could run the pipeline every week to retrain the model with the new data."
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "from azureml.pipeline.core import ScheduleRecurrence, Schedule\n",
        "\n",
        "# Submit the Pipeline every Monday at 00:00 UTC\n",
        "recurrence = ScheduleRecurrence(frequency=\"Week\", interval=1, week_days=[\"Monday\"], time_of_day=\"00:00\")\n",
        "\n",
        "weekly_schedule = Schedule.create(ws, name=\"weekly-diabetes-training\", \n",
        "                                  description=\"Based on time\",\n",
        "                                  pipeline_id=published_pipeline.id, \n",
        "                                  experiment_name='mslearn-diabetes-pipeline', \n",
        "                                  recurrence=recurrence)\n",
        "                                  \n",
        "print('Pipeline scheduled.')"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "Pipeline scheduled.\n"
        }
      ],
      "execution_count": 19,
      "metadata": {
        "gather": {
          "logged": 1633731043972
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "You can retrieve the schedules that are defined in the workspace like this:"
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "schedules = Schedule.list(ws)\n",
        "schedules"
      ],
      "outputs": [
        {
          "output_type": "execute_result",
          "execution_count": 20,
          "data": {
            "text/plain": "[Pipeline(Name: weekly-diabetes-training,\n Id: 05a4c31b-0777-4858-9469-77802dcff248,\n Status: Active,\n Pipeline Id: 2f4afe6d-247b-447d-a0d2-1d0e891bc8ba,\n Pipeline Endpoint Id: None,\n Recurrence Details: Runs at 0:00 on Monday every Week)]"
          },
          "metadata": {}
        }
      ],
      "execution_count": 20,
      "metadata": {
        "gather": {
          "logged": 1633731072500
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "You can check the latest run like this:"
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "pipeline_experiment = ws.experiments.get('mslearn-diabetes-pipeline')\n",
        "latest_run = list(pipeline_experiment.get_runs())[0]\n",
        "\n",
        "latest_run.get_details()"
      ],
      "outputs": [
        {
          "output_type": "execute_result",
          "execution_count": 21,
          "data": {
            "text/plain": "{'runId': 'e8b243f7-78f6-4e93-ba4b-7d7f5fb6f9fa',\n 'status': 'Completed',\n 'startTimeUtc': '2021-10-08T22:10:46.383934Z',\n 'endTimeUtc': '2021-10-08T22:10:48.527658Z',\n 'services': {},\n 'properties': {'azureml.git.repository_uri': 'https://github.com/JavierMedel/mslearn-dp100.git',\n  'mlflow.source.git.repoURL': 'https://github.com/JavierMedel/mslearn-dp100.git',\n  'azureml.git.branch': 'main',\n  'mlflow.source.git.branch': 'main',\n  'azureml.git.commit': '58d295a77569b9d101149cc915e0272e0f1fe78e',\n  'mlflow.source.git.commit': '58d295a77569b9d101149cc915e0272e0f1fe78e',\n  'azureml.git.dirty': 'True',\n  'azureml.runsource': 'azureml.PipelineRun',\n  'runSource': 'Unavailable',\n  'runType': 'Schedule',\n  'azureml.parameters': '{}',\n  'azureml.pipelineComponent': 'pipelinerun',\n  'azureml.pipelineid': '2f4afe6d-247b-447d-a0d2-1d0e891bc8ba'},\n 'inputDatasets': [],\n 'outputDatasets': [],\n 'logFiles': {'logs/azureml/executionlogs.txt': 'https://ict91502jmdl5971809827.blob.core.windows.net/azureml/ExperimentRun/dcid.e8b243f7-78f6-4e93-ba4b-7d7f5fb6f9fa/logs/azureml/executionlogs.txt?sv=2019-07-07&sr=b&sig=cpWAJfhcAwEHGlg1s5tweEeUGQHjph4FekBNzuNFcjI%3D&skoid=65509533-6487-43e3-a9e5-9135310d21ed&sktid=669832bc-1c49-401d-84ca-5fe95035ead2&skt=2021-10-08T21%3A36%3A10Z&ske=2021-10-10T05%3A46%3A10Z&sks=b&skv=2019-07-07&st=2021-10-08T22%3A01%3A43Z&se=2021-10-09T06%3A11%3A43Z&sp=r',\n  'logs/azureml/stderrlogs.txt': 'https://ict91502jmdl5971809827.blob.core.windows.net/azureml/ExperimentRun/dcid.e8b243f7-78f6-4e93-ba4b-7d7f5fb6f9fa/logs/azureml/stderrlogs.txt?sv=2019-07-07&sr=b&sig=%2F3b3WEqA2wSVpr3%2BG%2F%2BZBznw0gQImEZ4G%2Fa%2FOTsctGU%3D&skoid=65509533-6487-43e3-a9e5-9135310d21ed&sktid=669832bc-1c49-401d-84ca-5fe95035ead2&skt=2021-10-08T21%3A36%3A10Z&ske=2021-10-10T05%3A46%3A10Z&sks=b&skv=2019-07-07&st=2021-10-08T22%3A01%3A43Z&se=2021-10-09T06%3A11%3A43Z&sp=r',\n  'logs/azureml/stdoutlogs.txt': 'https://ict91502jmdl5971809827.blob.core.windows.net/azureml/ExperimentRun/dcid.e8b243f7-78f6-4e93-ba4b-7d7f5fb6f9fa/logs/azureml/stdoutlogs.txt?sv=2019-07-07&sr=b&sig=Emsvb%2BqKsEEM0D4lrri1bxYW6ilbr1PG2vD7%2BJXBvaI%3D&skoid=65509533-6487-43e3-a9e5-9135310d21ed&sktid=669832bc-1c49-401d-84ca-5fe95035ead2&skt=2021-10-08T21%3A36%3A10Z&ske=2021-10-10T05%3A46%3A10Z&sks=b&skv=2019-07-07&st=2021-10-08T22%3A01%3A43Z&se=2021-10-09T06%3A11%3A43Z&sp=r'},\n 'submittedBy': 'Francisco Javier Medel Medina'}"
          },
          "metadata": {}
        }
      ],
      "execution_count": 21,
      "metadata": {
        "gather": {
          "logged": 1633731103471
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "This is a simple example, designed to demonstrate the principle. In reality, you could build more sophisticated logic into the pipeline steps - for example, evaluating the model against some test data to calculate a performance metric like AUC or accuracy, comparing the metric to that of any previously registered versions of the model, and only registering the new model if it performs better.\n",
        "\n",
        "You can use the [Azure Machine Learning extension for Azure DevOps](https://marketplace.visualstudio.com/items?itemName=ms-air-aiagility.vss-services-azureml) to combine Azure ML pipelines with Azure DevOps pipelines (yes, it *is* confusing that they have the same name!) and integrate model retraining into a *continuous integration/continuous deployment (CI/CD)* process. For example you could use an Azure DevOps *build* pipeline to trigger an Azure ML pipeline that trains and registers a model, and when the model is registered it could trigger an Azure Devops *release* pipeline that deploys the model as a web service, along with the application or service that consumes the model."
      ],
      "metadata": {}
    }
  ],
  "metadata": {
    "kernelspec": {
      "name": "python3-azureml",
      "language": "python",
      "display_name": "Python 3.6 - AzureML"
    },
    "language_info": {
      "name": "python",
      "version": "3.6.9",
      "mimetype": "text/x-python",
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "pygments_lexer": "ipython3",
      "nbconvert_exporter": "python",
      "file_extension": ".py"
    },
    "kernel_info": {
      "name": "python3-azureml"
    },
    "nteract": {
      "version": "nteract-front-end@1.0.0"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}